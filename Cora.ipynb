{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 58,
      "id": "pmsI_OoWtg_s",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pmsI_OoWtg_s",
        "outputId": "db6e78d0-6854-4458-86bd-cf105bdbe815"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: BisPy in /usr/local/lib/python3.12/dist-packages (0.2.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from BisPy) (3.6)\n",
            "Requirement already satisfied: llist in /usr/local/lib/python3.12/dist-packages (from BisPy) (0.7.1)\n",
            "Requirement already satisfied: ogb in /usr/local/lib/python3.12/dist-packages (1.3.6)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from ogb) (2.9.0+cu126)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.12/dist-packages (from ogb) (2.0.2)\n",
            "Requirement already satisfied: tqdm>=4.29.0 in /usr/local/lib/python3.12/dist-packages (from ogb) (4.67.1)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from ogb) (1.6.1)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.12/dist-packages (from ogb) (2.2.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from ogb) (1.17.0)\n",
            "Requirement already satisfied: urllib3>=1.24.0 in /usr/local/lib/python3.12/dist-packages (from ogb) (2.5.0)\n",
            "Requirement already satisfied: outdated>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from ogb) (0.2.2)\n",
            "Requirement already satisfied: setuptools>=44 in /usr/local/lib/python3.12/dist-packages (from outdated>=0.2.0->ogb) (75.2.0)\n",
            "Requirement already satisfied: littleutils in /usr/local/lib/python3.12/dist-packages (from outdated>=0.2.0->ogb) (0.2.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from outdated>=0.2.0->ogb) (2.32.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.24.0->ogb) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.24.0->ogb) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.24.0->ogb) (2025.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=0.20.0->ogb) (1.16.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=0.20.0->ogb) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=0.20.0->ogb) (3.6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.6.0->ogb) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.6.0->ogb) (4.15.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.6.0->ogb) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.6.0->ogb) (3.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.6.0->ogb) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.6.0->ogb) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.6.0->ogb) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.6.0->ogb) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.6.0->ogb) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.6.0->ogb) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.6.0->ogb) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.6.0->ogb) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.6.0->ogb) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.6.0->ogb) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.6.0->ogb) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.6.0->ogb) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.6.0->ogb) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=1.6.0->ogb) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.6.0->ogb) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.6.0->ogb) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.6.0->ogb) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.6.0->ogb) (3.5.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.6.0->ogb) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.6.0->ogb) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->outdated>=0.2.0->ogb) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->outdated>=0.2.0->ogb) (3.11)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->outdated>=0.2.0->ogb) (2025.11.12)\n",
            "Requirement already satisfied: torch-geometric in /usr/local/lib/python3.12/dist-packages (2.7.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.13.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (2025.3.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.1.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (2.0.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.2.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.6.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (1.22.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch-geometric) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (2025.11.12)\n",
            "Requirement already satisfied: typing-extensions>=4.2 in /usr/local/lib/python3.12/dist-packages (from aiosignal>=1.4.0->aiohttp->torch-geometric) (4.15.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install BisPy\n",
        "!pip install ogb\n",
        "!pip install torch-geometric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "id": "57355aff-2d79-4c56-9e9f-20b5d9673c31",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "57355aff-2d79-4c56-9e9f-20b5d9673c31",
        "outputId": "df3760d4-7862-4cab-b22e-466f3a8e6bc4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.utils import to_networkx\n",
        "import pandas as pd\n",
        "from torch_geometric.datasets import Planetoid, CoraFull, Yelp, WebKB, Actor\n",
        "import os\n",
        "import bispy\n",
        "from bispy import compute_maximum_bisimulation, Algorithms\n",
        "from bispy.dovier_piazza_policriti.dovier_piazza_policriti import dovier_piazza_policriti_partition\n",
        "from bispy.dovier_piazza_policriti.ranked_partition import RankedPartition\n",
        "from bispy.dovier_piazza_policriti.dovier_piazza_policriti import dovier_piazza_policriti, collapse, build_block_counterimage, split_upper_ranks\n",
        "from bispy.utilities.rank_computation import compute_rank\n",
        "from bispy.utilities.graph_decorator import decorate_nx_graph, decorate_bispy_graph,as_bispy_graph,to_tuple_list\n",
        "from bispy.utilities import *\n",
        "import numpy as np\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "from scipy.cluster.hierarchy import linkage, dendrogram, fcluster\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "id": "8b10c669-823c-4cfe-a6b5-efebd3f3c8f3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8b10c669-823c-4cfe-a6b5-efebd3f3c8f3",
        "outputId": "10e20ad3-ee61-422e-db0f-38556cce5973"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of nodes: 2708\n",
            "Number of edges: 5429\n"
          ]
        }
      ],
      "source": [
        "# Create an empty NetworkX graph\n",
        "from torch_geometric.utils import from_networkx\n",
        "G = nx.DiGraph()\n",
        "node_map = {}\n",
        "\n",
        "def get_key(val, node_map):\n",
        "    for key, value in node_map.items():\n",
        "        if val == value:\n",
        "            return key\n",
        "    return \"key doesn't exist\"\n",
        "\n",
        "\n",
        "# Driver Code\n",
        "# my_dict = {\"Java\": 100, \"Python\": 112, \"C\": 11}\n",
        "\n",
        "# print(get_key(100))\n",
        "# print(get_key(11))\n",
        "\n",
        "# Read node features and labels from 'cora.content'\n",
        "with open('/content/gdrive/My Drive/GNN_Sparsification/Algorithms/cora.content', 'r') as content_file:\n",
        "    i = 0\n",
        "    for line in content_file:\n",
        "        data = line.strip().split('\\t')\n",
        "        node_id = data[0]\n",
        "        features = [float(x) for x in data[1:-1]]\n",
        "        label = data[-1]\n",
        "        node_map[i] = node_id\n",
        "        # print(node_id)\n",
        "        # Add node to the graph with features and label\n",
        "        G.add_node(i, features=features, label=label)\n",
        "        i+=1\n",
        "\n",
        "# Read edges from 'cora.cites'\n",
        "with open('/content/gdrive/My Drive/GNN_Sparsification/Algorithms/cora.cites', 'r') as cites_file:\n",
        "    for line in cites_file:\n",
        "        source, target = line.strip().split('\\t')\n",
        "        source = get_key(source, node_map)\n",
        "        target = get_key(target, node_map)\n",
        "        G.add_edge(source, target)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "data_path = '/content/gdrive/MyDrive/GNN_Sparsification/Algorithms/cora.content'  # Update with the correct path\n",
        "# column_names = [\"paper_id\"] + [f\"attr_{i}\" for i in range(1433)] + [\"subject\"]\n",
        "column_names = [f\"attr_{i}\" for i in range(1433)] + [\"subject\"]\n",
        "df = pd.read_csv(data_path, sep='\\t', header=None, names=column_names)\n",
        "\n",
        "# Display the first few rows\n",
        "df = df.iloc[:,1:-1]\n",
        "\n",
        "# Access a specific attribute for a specific node\n",
        "# attribute_values_for_node_0 = df.loc[0, \"attr_0\":\"attr_1432\"]\n",
        "\n",
        "# Access the subject label for a specific node\n",
        "# subject_label_for_node_0 = df.loc[0, \"subject\"]\n",
        "# Print basic graph information\n",
        "data = from_networkx(G)\n",
        "\n",
        "print(\"Number of nodes:\", G.number_of_nodes())\n",
        "print(\"Number of edges:\", G.number_of_edges())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RT_-53z7m4SY",
        "outputId": "92ae2ae4-653f-48d3-c263-cadc02407e02"
      },
      "id": "RT_-53z7m4SY",
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "id": "mtzx3e-XBYza",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mtzx3e-XBYza",
        "outputId": "fb047fd2-1354-45c1-9988-a4bcdf7eaf26"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Data(x=[2708, 1433], edge_index=[2, 10556], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708])"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ],
      "source": [
        "# Cora\n",
        "from torch_geometric.datasets import Planetoid, CoraFull, Yelp, WebKB\n",
        "\n",
        "dataset = Planetoid(root='/tmp/Cora', name='Cora')\n",
        "# dataset = Yelp(root='Yelp')\n",
        "cora = dataset[0]\n",
        "cora.y = torch.squeeze(cora.y)\n",
        "cora"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "id": "w6quy9u3CMOr",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w6quy9u3CMOr",
        "outputId": "1eaf6be8-538c-435d-849c-e1fb987e07a3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Data(x=[2708, 1433], edge_index=[2, 5429], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708])"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ],
      "source": [
        "cora.edge_index = data.edge_index\n",
        "cora"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "id": "c4fb6cf9-cafd-4b47-a198-c0d292b49a98",
      "metadata": {
        "id": "c4fb6cf9-cafd-4b47-a198-c0d292b49a98"
      },
      "outputs": [],
      "source": [
        "# Load tensor from .pt file\n",
        "#loaded_tensor = torch.load('ARXIV_SPAR.pt')\n",
        "#data.edge_index = loaded_tensor.edge_index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "id": "70bd6cdd-7106-47f4-863f-80d99846bf37",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "70bd6cdd-7106-47f4-863f-80d99846bf37",
        "outputId": "aa9dba4c-9149-4e6c-ca3f-7a1f91fe1722"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Data(edge_index=[2, 5429], features=[2708, 1433], label=[2708], num_nodes=2708)"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ],
      "source": [
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "id": "99d8788e-230d-4ecd-a7cc-de797f1eb7c6",
      "metadata": {
        "id": "99d8788e-230d-4ecd-a7cc-de797f1eb7c6"
      },
      "outputs": [],
      "source": [
        "import copy\n",
        "from torch_geometric.utils import subgraph\n",
        "train_mask = torch.rand(data.num_nodes) < 0.8\n",
        "test_mask = ~train_mask\n",
        "tested_elements =  torch.nonzero(test_mask==True).squeeze()\n",
        "tested_elements = tested_elements.tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "id": "6rzsaQpkC7nE",
      "metadata": {
        "id": "6rzsaQpkC7nE"
      },
      "outputs": [],
      "source": [
        "file_path = \"/content/drive/MyDrive/GNN_Sparsification/20%_cora_train_mask.pt\"\n",
        "\n",
        "# Save the binary tensor mask to a .pt file\n",
        "torch.save(train_mask, file_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "id": "f9Pgv942PzrJ",
      "metadata": {
        "id": "f9Pgv942PzrJ"
      },
      "outputs": [],
      "source": [
        "train_mask = torch.load(\"/content/drive/MyDrive/GNN_Sparsification/20%_cora_train_mask.pt\")\n",
        "test_mask = ~train_mask\n",
        "tested_elements =  torch.nonzero(test_mask==True).squeeze()\n",
        "tested_elements = tested_elements.tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "id": "cca827fe-ffd6-4f8d-8529-06334af2d47a",
      "metadata": {
        "id": "cca827fe-ffd6-4f8d-8529-06334af2d47a"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.utils import to_networkx\n",
        "\n",
        "\n",
        "# Convert PyG graph to NetworkX graph\n",
        "def pyg_to_networkx(pyg_data):\n",
        "    edge_index = pyg_data.edge_index\n",
        "    num_nodes = pyg_data.num_nodes\n",
        "    edge_list = edge_index.t().tolist()\n",
        "    G = nx.DiGraph()\n",
        "    G.add_nodes_from(range(num_nodes))\n",
        "    G.add_edges_from(edge_list)\n",
        "    return G\n",
        "\n",
        "networkx_graph = pyg_to_networkx(cora)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2a6b2650-cb98-4c20-bf7e-55e462d6b7bd",
      "metadata": {
        "id": "2a6b2650-cb98-4c20-bf7e-55e462d6b7bd"
      },
      "source": [
        "# Radius-based K-hops Induced Subgraph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "id": "80e9851a-ee6b-4198-835f-245067795c5f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "80e9851a-ee6b-4198-835f-245067795c5f",
        "outputId": "855174fa-f737-439b-a4d7-52483cf4fece"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        }
      ],
      "source": [
        "nodes_to_find_neighbors = tested_elements\n",
        "neighbors = set()\n",
        "up_to_k_hop_neighbors = []\n",
        "up_to_k_hop_neighbors_list = []\n",
        "k = 1\n",
        "# G = nx.Graph()\n",
        "G = nx.DiGraph()\n",
        "\n",
        "for i in range(k):\n",
        "  # Iterate through the nodes in your set\n",
        "  print(i)\n",
        "  neighbors = set()\n",
        "  for node in nodes_to_find_neighbors:\n",
        "    # Use the neighbors() function to get 1-hop neighbors and add them to the set\n",
        "    neighbors.update(networkx_graph.neighbors(node))\n",
        "    neighbors.update(networkx_graph.predecessors(node))\n",
        "\n",
        "    if i == 0:\n",
        "      G.add_node(node)\n",
        "\n",
        "      for neighbor in networkx_graph.neighbors(node):\n",
        "        if neighbor not in nodes_to_find_neighbors:\n",
        "          G.add_edge(node, neighbor)\n",
        "\n",
        "      for neighbor in networkx_graph.predecessors(node):\n",
        "        if neighbor not in nodes_to_find_neighbors:\n",
        "          G.add_edge(neighbor, node)\n",
        "\n",
        "\n",
        "    else:\n",
        "      for neighbor in networkx_graph.neighbors(node):\n",
        "        if neighbor not in up_to_k_hop_neighbors_list:\n",
        "          G.add_edge(node, neighbor)\n",
        "\n",
        "      for neighbor in networkx_graph.predecessors(node):\n",
        "        if neighbor not in up_to_k_hop_neighbors_list:\n",
        "          G.add_edge(neighbor, node)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # ensure the disjoint property\n",
        "  if i > 0:\n",
        "    for ele in up_to_k_hop_neighbors:\n",
        "      neighbors_list = list(set(list(neighbors)).difference(set(ele)))\n",
        "    neighbors_list = list(set(neighbors).difference(set(tested_elements)))\n",
        "\n",
        "  if i == 0:\n",
        "    neighbors_list = list(set(neighbors).difference(set(tested_elements)))\n",
        "    up_to_k_hop_neighbors_list += tested_elements\n",
        "\n",
        "  nodes_to_find_neighbors = neighbors_list\n",
        "  up_to_k_hop_neighbors.append(neighbors_list)\n",
        "  up_to_k_hop_neighbors_list += neighbors_list"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3a9063da-4ffa-423b-9fa7-bc41654e3f4b",
      "metadata": {
        "id": "3a9063da-4ffa-423b-9fa7-bc41654e3f4b"
      },
      "source": [
        "# Diameter-based K-hops Induced Subgraph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "id": "dbbde73f-eb20-4fe4-ab4b-42b264323112",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dbbde73f-eb20-4fe4-ab4b-42b264323112",
        "outputId": "c3e9a19a-fdf1-4b06-a725-bdb276706375"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        }
      ],
      "source": [
        "nodes_to_find_neighbors = tested_elements\n",
        "neighbors = set()\n",
        "up_to_k_hop_neighbors = []\n",
        "up_to_k_hop_neighbors_list = []\n",
        "k = 1\n",
        "# G = nx.Graph()\n",
        "G = nx.DiGraph()\n",
        "\n",
        "for i in range(k):\n",
        "  # Iterate through the nodes in your set\n",
        "  print(i)\n",
        "  neighbors = set()\n",
        "  for node in nodes_to_find_neighbors:\n",
        "    # Use the neighbors() function to get 1-hop neighbors and add them to the set\n",
        "    neighbors.update(networkx_graph.predecessors(node))\n",
        "\n",
        "    if i == 0:\n",
        "      G.add_node(node)\n",
        "\n",
        "      for neighbor in networkx_graph.predecessors(node):\n",
        "        if neighbor not in nodes_to_find_neighbors:\n",
        "          G.add_edge(neighbor, node)\n",
        "\n",
        "\n",
        "    else:\n",
        "      for neighbor in networkx_graph.predecessors(node):\n",
        "        # if neighbor not in up_to_k_hop_neighbors_list:\n",
        "        if neighbor not in nodes_to_find_neighbors:\n",
        "          G.add_edge(neighbor, node)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # ensure the disjoint property\n",
        "  if i > 0:\n",
        "    for ele in up_to_k_hop_neighbors:\n",
        "      neighbors_list = list(set(list(neighbors)).difference(set(ele)))\n",
        "    neighbors_list = list(set(neighbors).difference(set(tested_elements)))\n",
        "\n",
        "  if i == 0:\n",
        "    neighbors_list = list(set(neighbors).difference(set(tested_elements)))\n",
        "    up_to_k_hop_neighbors_list += tested_elements\n",
        "\n",
        "  nodes_to_find_neighbors = neighbors_list\n",
        "  up_to_k_hop_neighbors.append(neighbors_list)\n",
        "  up_to_k_hop_neighbors_list += neighbors_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "id": "cb28c82d-e076-497e-9486-a3394d9afbd7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cb28c82d-e076-497e-9486-a3394d9afbd7",
        "outputId": "e38d6b6a-b5ab-44de-dd24-0ce4b1b5c877"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of nodes: 1071\n",
            "Number of edges: 858\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ],
      "source": [
        "num_nodes = G.number_of_nodes()\n",
        "num_edges = G.number_of_edges()\n",
        "\n",
        "print(\"Number of nodes:\", num_nodes)\n",
        "print(\"Number of edges:\", num_edges)\n",
        "\n",
        "\n",
        "partition = compute_maximum_bisimulation(G)\n",
        "len(partition)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "id": "EVRffqQExaiX",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EVRffqQExaiX",
        "outputId": "265fc9f6-9439-4833-972e-36fce7f2ebf8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of nodes: 1071\n",
            "Number of edges: 858\n",
            "Execution time: 0.03502845764160156 seconds\n"
          ]
        }
      ],
      "source": [
        "num_nodes = G.number_of_nodes()\n",
        "num_edges = G.number_of_edges()\n",
        "\n",
        "print(\"Number of nodes:\", num_nodes)\n",
        "print(\"Number of edges:\", num_edges)\n",
        "\n",
        "import time\n",
        "\n",
        "# Measure the execution time\n",
        "start_time = time.time()\n",
        "\n",
        "partition = compute_maximum_bisimulation(G)\n",
        "len(partition)\n",
        "\n",
        "end_time = time.time()\n",
        "execution_time = end_time - start_time\n",
        "\n",
        "\n",
        "\n",
        "print(f\"Execution time: {execution_time} seconds\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "id": "q2yTDzPaQP5S",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q2yTDzPaQP5S",
        "outputId": "54b97614-f3de-4c08-df1f-c6d73359cab2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Data(x=[2708, 1433], edge_index=[2, 5429], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708])"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ],
      "source": [
        "cora"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "id": "bY1_sd3UowSC",
      "metadata": {
        "id": "bY1_sd3UowSC"
      },
      "outputs": [],
      "source": [
        "#cora_FGC = torch.load('gdrive/My Drive/GNN_Sparsification/Coarsened_CORA.pt')\n",
        "#cora_FGC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "id": "frzywns2ih6U",
      "metadata": {
        "id": "frzywns2ih6U"
      },
      "outputs": [],
      "source": [
        "#edge_indices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "id": "y3u_qdhSSZJj",
      "metadata": {
        "id": "y3u_qdhSSZJj"
      },
      "outputs": [],
      "source": [
        "#cora_FGC.edge_index = edge_indices\n",
        "#cora_FGC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "id": "mU7Vz8E3iybu",
      "metadata": {
        "id": "mU7Vz8E3iybu"
      },
      "outputs": [],
      "source": [
        "#torch.save(cora_FGC,'gdrive/My Drive/GNN_Sparsification/cora_FGC.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "id": "c18ef3aa-dca4-42b5-ba82-7a974c077815",
      "metadata": {
        "id": "c18ef3aa-dca4-42b5-ba82-7a974c077815"
      },
      "outputs": [],
      "source": [
        "tuple_list = partition\n",
        "def find_tuple_index_with_integer(list_of_tuples, integer):\n",
        "    return next((index for index, tup in enumerate(list_of_tuples) if integer in tup), -1)\n",
        "\n",
        "# Sort the list by the number of elements in each tuple\n",
        "sorted_list = sorted(tuple_list, key=lambda x: len(x), reverse=True)\n",
        "\n",
        "indices = []\n",
        "list_of_lists = [list(t) for t in sorted_list]\n",
        "\n",
        "for ele in tested_elements:\n",
        "  id = find_tuple_index_with_integer(sorted_list, ele)\n",
        "  if len(list_of_lists[id]) > 1:\n",
        "    list_of_lists[id].remove(ele)\n",
        "    list_of_lists.append([ele])\n",
        "    indices.append(len(list_of_lists)-1)\n",
        "  else:\n",
        "    indices.append(id)\n",
        "\n",
        "list_of_tuples = [tuple(inner_list) for inner_list in list_of_lists]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "id": "4c329ef2-9470-4837-b973-7f6b3751e9c9",
      "metadata": {
        "id": "4c329ef2-9470-4837-b973-7f6b3751e9c9"
      },
      "outputs": [],
      "source": [
        "i = 0\n",
        "while len(list_of_lists[i])>1:\n",
        "    # print(i)\n",
        "\n",
        "    Z = linkage(data.x[list_of_tuples[i],:], method='average', metric='cosine')\n",
        "    threshold = 0.6 * np.max(Z[:, 2])\n",
        "    clusters = fcluster(Z, threshold, criterion='distance')\n",
        "\n",
        "    # Get cluster labels for each data point\n",
        "    labels = clusters\n",
        "\n",
        "    # Sample tuple to split\n",
        "    data_tuple = list_of_tuples[i]\n",
        "\n",
        "    # Create a dictionary to store split data\n",
        "    split_data = {}\n",
        "\n",
        "    # Iterate through the labels and tuple elements\n",
        "    for label, value in zip(labels, data_tuple):\n",
        "      if label not in split_data:\n",
        "        split_data[label] = []\n",
        "      split_data[label].append(value)\n",
        "\n",
        "    # Convert the dictionary to a list of tuples (if needed)\n",
        "    split_tuples = [tuple(values) for key, values in split_data.items()]\n",
        "    list_of_tuples.pop(i)\n",
        "    j = 0\n",
        "    for values in split_tuples:\n",
        "      if j == 0:\n",
        "        list_of_tuples.insert(0, values)\n",
        "      else:\n",
        "        list_of_tuples.insert(len(list_of_tuples), values)\n",
        "      j+=1\n",
        "\n",
        "    i+=1\n",
        "\n",
        "result_dict = {element: index for index, tup in enumerate(list_of_tuples) for element in tup}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a343eb51-3321-4813-bfa1-a55f77bf2ae2",
      "metadata": {
        "id": "a343eb51-3321-4813-bfa1-a55f77bf2ae2"
      },
      "source": [
        "# Alpha = 0.1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "id": "4a492604-ef39-4c1a-a9a5-cb90d26862ca",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4a492604-ef39-4c1a-a9a5-cb90d26862ca",
        "outputId": "04e144af-0289-42c5-8b2e-0475f04f2fd4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of nodes: 581\n",
            "Number of edges: 416\n"
          ]
        }
      ],
      "source": [
        "BCG = nx.DiGraph()\n",
        "import random\n",
        "\n",
        "for i in range(len(list_of_tuples)):\n",
        "  BCG.add_node(i)\n",
        "\n",
        "for edge in G.edges():\n",
        "    source, target = edge\n",
        "    BCG.add_edge(result_dict[source], result_dict[target])\n",
        "\n",
        "# Get the number of nodes and edges\n",
        "num_nodes = BCG.number_of_nodes()\n",
        "num_edges = BCG.number_of_edges()\n",
        "\n",
        "print(\"Number of nodes:\", num_nodes)\n",
        "print(\"Number of edges:\", num_edges)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1f4b5cf2-827d-4b28-a617-78e3d2f3051b",
      "metadata": {
        "id": "1f4b5cf2-827d-4b28-a617-78e3d2f3051b"
      },
      "source": [
        "# Alpha = 0.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "id": "765addc6-788e-409c-930c-02dce0f919f0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "765addc6-788e-409c-930c-02dce0f919f0",
        "outputId": "4afe0719-afed-45af-a81c-2e85d6d55d46"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of nodes: 581\n",
            "Number of edges: 416\n"
          ]
        }
      ],
      "source": [
        "BCG = nx.DiGraph()\n",
        "import random\n",
        "\n",
        "for i in range(len(list_of_tuples)):\n",
        "  BCG.add_node(i)\n",
        "\n",
        "for edge in G.edges():\n",
        "    source, target = edge\n",
        "    BCG.add_edge(result_dict[source], result_dict[target])\n",
        "\n",
        "# Get the number of nodes and edges\n",
        "num_nodes = BCG.number_of_nodes()\n",
        "num_edges = BCG.number_of_edges()\n",
        "\n",
        "print(\"Number of nodes:\", num_nodes)\n",
        "print(\"Number of edges:\", num_edges)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ItLJGVOHbMio",
      "metadata": {
        "id": "ItLJGVOHbMio"
      },
      "source": [
        "# Alpha = 0.3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "id": "xXx002RvbMr_",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xXx002RvbMr_",
        "outputId": "4e779f4f-41ce-4973-a605-60ac4aca9c1e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of nodes: 581\n",
            "Number of edges: 416\n"
          ]
        }
      ],
      "source": [
        "BCG = nx.DiGraph()\n",
        "import random\n",
        "\n",
        "for i in range(len(list_of_tuples)):\n",
        "  BCG.add_node(i)\n",
        "\n",
        "for edge in G.edges():\n",
        "    source, target = edge\n",
        "    BCG.add_edge(result_dict[source], result_dict[target])\n",
        "\n",
        "# Get the number of nodes and edges\n",
        "num_nodes = BCG.number_of_nodes()\n",
        "num_edges = BCG.number_of_edges()\n",
        "\n",
        "print(\"Number of nodes:\", num_nodes)\n",
        "print(\"Number of edges:\", num_edges)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "w6OFpCrrl8PT",
      "metadata": {
        "id": "w6OFpCrrl8PT"
      },
      "source": [
        "# 0.4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "id": "WMaC6q-7l8XG",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WMaC6q-7l8XG",
        "outputId": "910f5854-9d60-41cf-9fbd-f71855ce45ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of nodes: 581\n",
            "Number of edges: 416\n"
          ]
        }
      ],
      "source": [
        "BCG = nx.DiGraph()\n",
        "import random\n",
        "\n",
        "for i in range(len(list_of_tuples)):\n",
        "  BCG.add_node(i)\n",
        "\n",
        "for edge in G.edges():\n",
        "    source, target = edge\n",
        "    BCG.add_edge(result_dict[source], result_dict[target])\n",
        "\n",
        "# Get the number of nodes and edges\n",
        "num_nodes = BCG.number_of_nodes()\n",
        "num_edges = BCG.number_of_edges()\n",
        "\n",
        "print(\"Number of nodes:\", num_nodes)\n",
        "print(\"Number of edges:\", num_edges)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "NzoxaG9jnkj2",
      "metadata": {
        "id": "NzoxaG9jnkj2"
      },
      "source": [
        "# 0.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "id": "ncyOCvnLnktb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ncyOCvnLnktb",
        "outputId": "8abadd59-5149-47ef-d3e9-67164033260a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of nodes: 581\n",
            "Number of edges: 416\n"
          ]
        }
      ],
      "source": [
        "BCG = nx.DiGraph()\n",
        "import random\n",
        "\n",
        "for i in range(len(list_of_tuples)):\n",
        "  BCG.add_node(i)\n",
        "\n",
        "for edge in G.edges():\n",
        "    source, target = edge\n",
        "    BCG.add_edge(result_dict[source], result_dict[target])\n",
        "\n",
        "# Get the number of nodes and edges\n",
        "num_nodes = BCG.number_of_nodes()\n",
        "num_edges = BCG.number_of_edges()\n",
        "\n",
        "print(\"Number of nodes:\", num_nodes)\n",
        "print(\"Number of edges:\", num_edges)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "lPGuuLSaczJh",
      "metadata": {
        "id": "lPGuuLSaczJh"
      },
      "source": [
        "# 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "id": "OQWIE2m0czRi",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OQWIE2m0czRi",
        "outputId": "cb107b39-9c2e-4918-da7c-b323822d2d7f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of nodes: 581\n",
            "Number of edges: 416\n"
          ]
        }
      ],
      "source": [
        "result_dict = {element: index for index, tup in enumerate(list_of_tuples) for element in tup}\n",
        "\n",
        "BCG = nx.DiGraph()\n",
        "import random\n",
        "\n",
        "for i in range(len(list_of_tuples)):\n",
        "  BCG.add_node(i)\n",
        "\n",
        "for edge in G.edges():\n",
        "    source, target = edge\n",
        "    BCG.add_edge(result_dict[source], result_dict[target])\n",
        "\n",
        "# Get the number of nodes and edges\n",
        "num_nodes = BCG.number_of_nodes()\n",
        "num_edges = BCG.number_of_edges()\n",
        "\n",
        "print(\"Number of nodes:\", num_nodes)\n",
        "print(\"Number of edges:\", num_edges)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "id": "461345c3-8577-410f-a752-8b5af9195c4f",
      "metadata": {
        "id": "461345c3-8577-410f-a752-8b5af9195c4f"
      },
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "import random\n",
        "\n",
        "new_x = torch.zeros(num_nodes,cora.x.shape[1])\n",
        "new_y = torch.zeros(num_nodes)\n",
        "for i in range(len(list_of_tuples)):\n",
        "  new_x[i,:] = torch.mean(cora.x[list(list_of_tuples[i]),:], axis = 0)\n",
        "  EC = list_of_tuples[i]\n",
        "  L = []\n",
        "  for ele in EC:\n",
        "    L.append(int(cora.y[ele].numpy()))\n",
        "\n",
        "  keys = list(Counter(L).keys())\n",
        "  frequencies = list(Counter(L).values())\n",
        "\n",
        "  # Randomly select a key based on frequencies\n",
        "  random_key = random.choices(keys, frequencies)[0]\n",
        "  new_y[i] = int(random_key)\n",
        "\n",
        "edges = list(BCG.edges())\n",
        "\n",
        "# Create a dictionary to map node labels to integer indices\n",
        "node_mapping = {node: index for index, node in enumerate(BCG.nodes())}\n",
        "\n",
        "# Convert the edges to indices using the node_mapping\n",
        "new_edge_index = [[node_mapping[source], node_mapping[target]] for source, target in edges]\n",
        "new_edge_index = torch.tensor(new_edge_index, dtype=torch.long).t().contiguous()\n",
        "\n",
        "data_new1 = copy.copy(data)\n",
        "data_new1.x = new_x\n",
        "data_new1.y = new_y.long()\n",
        "data_new1.edge_index = new_edge_index\n",
        "data_new1.num_nodes = len(new_y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "id": "MTNSDxRJM8nm",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MTNSDxRJM8nm",
        "outputId": "550647bc-cfcc-419e-e7db-90c9b6013c6d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Data(edge_index=[2, 5429], features=[2708, 1433], label=[2708], num_nodes=2708)"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ],
      "source": [
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "id": "NbsbtYVtNChR",
      "metadata": {
        "id": "NbsbtYVtNChR"
      },
      "outputs": [],
      "source": [
        "data.y = cora.y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "id": "83bdbbfa-74a0-4186-bcda-a57da03ff54e",
      "metadata": {
        "id": "83bdbbfa-74a0-4186-bcda-a57da03ff54e"
      },
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "import random\n",
        "import copy\n",
        "from collections import Counter\n",
        "\n",
        "new_x = torch.zeros(len(list(G.nodes)),cora.x.shape[1])\n",
        "new_y = torch.zeros(len(list(G.nodes)))\n",
        "list_itr = list(G.nodes)\n",
        "for i in range(len(list(G.nodes))):\n",
        "  new_x[i,:] = cora.x[list_itr[i],:]\n",
        "  new_y[i] = int(cora.y[list_itr[i]])\n",
        "\n",
        "edges = list(G.edges())\n",
        "\n",
        "# Create a dictionary to map node labels to integer indices\n",
        "node_mapping = {node: index for index, node in enumerate(G.nodes())}\n",
        "\n",
        "# Convert the edges to indices using the node_mapping\n",
        "new_edge_index = [[node_mapping[source], node_mapping[target]] for source, target in edges]\n",
        "new_edge_index = torch.tensor(new_edge_index, dtype=torch.long).t().contiguous()\n",
        "\n",
        "\n",
        "data_new1 = copy.copy(data)\n",
        "data_new1.x = new_x\n",
        "data_new1.y = new_y.long()\n",
        "data_new1.edge_index = new_edge_index\n",
        "data_new1.num_nodes = len(new_y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "id": "NOXXeXDvzctj",
      "metadata": {
        "id": "NOXXeXDvzctj"
      },
      "outputs": [],
      "source": [
        "torch.save(data_new1, '/content/drive/My Drive/GNN_Sparsification/20%_Induced_cora.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "id": "qJWrm14n1rAL",
      "metadata": {
        "id": "qJWrm14n1rAL"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from scipy.spatial.distance import euclidean\n",
        "from scipy.cluster.hierarchy import linkage, fcluster\n",
        "import numpy as np\n",
        "\n",
        "def exclude_tested_elements_from_MB(partition, tested_elements):\n",
        "    tuple_dict = {}\n",
        "    indices = []\n",
        "\n",
        "    tuple_list = partition\n",
        "\n",
        "    # Sort the list by the number of elements in each tuple\n",
        "    sorted_list = sorted(tuple_list, key=lambda x: len(x), reverse=True)\n",
        "\n",
        "    list_of_lists = [list(t) for t in sorted_list]\n",
        "\n",
        "    # Convert tuples to lists and create a dictionary with elements as keys and their corresponding tuple index as values\n",
        "    for idx, tpl in enumerate(list_of_lists):\n",
        "        tpl_list = list(tpl)\n",
        "        for ele in tpl_list:\n",
        "            tuple_dict[ele] = idx\n",
        "        list_of_lists[idx] = tpl_list\n",
        "\n",
        "    # Update the dictionary and indices based on tested elements\n",
        "    for ele in tested_elements:\n",
        "        if ele in tuple_dict:\n",
        "            idx = tuple_dict[ele]\n",
        "            if len(list_of_lists[idx]) > 1:\n",
        "                list_of_lists[idx].remove(ele)\n",
        "                list_of_lists.append([ele])\n",
        "                tuple_dict[ele] = len(list_of_lists) - 1\n",
        "                indices.append(len(list_of_lists) - 1)\n",
        "            else:\n",
        "                indices.append(idx)\n",
        "\n",
        "    return list_of_lists, indices\n",
        "\n",
        "def alpha_Sparsification(list_of_lists, data, alpha):\n",
        "  list_of_tuples = [tuple(inner_list) for inner_list in list_of_lists]\n",
        "  i = 0\n",
        "  while len(list_of_lists[i])>1:\n",
        "\n",
        "      Z = linkage(data.x[list_of_tuples[i],:].detach().numpy(), method='average', metric='cosine')\n",
        "      threshold = alpha * np.max(Z[:, 2])\n",
        "      clusters = fcluster(Z, threshold, criterion='distance')\n",
        "\n",
        "      # Get cluster labels for each data point\n",
        "      labels = clusters\n",
        "\n",
        "\n",
        "      # Z = linkage(data.x[list_of_tuples[i],:], method='average', metric='euclidean')\n",
        "      # threshold = alpha * np.max(Z[:, 2])\n",
        "      # clusters = fcluster(Z, threshold, criterion='distance')\n",
        "\n",
        "      # # Get cluster labels for each data point\n",
        "      # labels = clusters\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "      # Sample tuple to split\n",
        "      data_tuple = list_of_tuples[i]\n",
        "\n",
        "      # Create a dictionary to store split data\n",
        "      split_data = {}\n",
        "\n",
        "      # Iterate through the labels and tuple elements\n",
        "      for label, value in zip(labels, data_tuple):\n",
        "        if label not in split_data:\n",
        "          split_data[label] = []\n",
        "        split_data[label].append(value)\n",
        "\n",
        "      # Convert the dictionary to a list of tuples (if needed)\n",
        "      split_tuples = [tuple(values) for key, values in split_data.items()]\n",
        "      list_of_tuples.pop(i)\n",
        "      j = 0\n",
        "      for values in split_tuples:\n",
        "        if j == 0:\n",
        "          list_of_tuples.insert(0, values)\n",
        "        else:\n",
        "          list_of_tuples.insert(len(list_of_tuples), values)\n",
        "        j+=1\n",
        "\n",
        "      i+=1\n",
        "\n",
        "  result_dict = {element: index for index, tup in enumerate(list_of_tuples) for element in tup}\n",
        "\n",
        "  return list_of_tuples, result_dict\n",
        "\n",
        "# def alpha_Sparsification(list_of_lists, data, alpha):\n",
        "#     list_of_tuples = [tuple(inner_list) for inner_list in list_of_lists]\n",
        "#     i = 0\n",
        "#     while i<len(list_of_lists):\n",
        "#         if len(list_of_lists[i])>1:\n",
        "#             Z = linkage(data.x[list_of_tuples[i],:], method='average', metric='cosine')\n",
        "#             threshold = alpha * np.max(Z[:, 2])\n",
        "#             clusters = fcluster(Z, threshold, criterion='distance')\n",
        "#             # Get cluster labels for each data point\n",
        "#             labels = clusters\n",
        "#             # Sample tuple to split\n",
        "#             data_tuple = list_of_tuples[i]\n",
        "#             # Create a dictionary to store split data\n",
        "#             split_data = {}\n",
        "#           # Iterate through the labels and tuple elements\n",
        "#             for label, value in zip(labels, data_tuple):\n",
        "#                 if label not in split_data:\n",
        "#                     split_data[label] = []\n",
        "#                 split_data[label].append(value)\n",
        "\n",
        "#           # Convert the dictionary to a list of tuples (if needed)\n",
        "#             split_tuples = [tuple(values) for key, values in split_data.items()]\n",
        "#             list_of_tuples.pop(i)\n",
        "#             j = 0\n",
        "#             for values in split_tuples:\n",
        "#                 if j == 0:\n",
        "#                     list_of_tuples.insert(0, values)\n",
        "#                 else:\n",
        "#                     list_of_tuples.insert(len(list_of_tuples), values)\n",
        "#                 j+=1\n",
        "\n",
        "#         i+=1\n",
        "\n",
        "#     result_dict = {element: index for index, tup in enumerate(list_of_tuples) for element in tup}\n",
        "#     return list_of_tuples, result_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "id": "VPU1xdHh1rDC",
      "metadata": {
        "id": "VPU1xdHh1rDC"
      },
      "outputs": [],
      "source": [
        "def Sparisified_G_NX(list_of_tuples, result_dict, data):\n",
        "  BCG = nx.DiGraph()\n",
        "\n",
        "  for i in range(len(list_of_tuples)):\n",
        "    BCG.add_node(i)\n",
        "\n",
        "  for edge in G.edges():\n",
        "      source, target = edge\n",
        "      # if cosine_similarity(data.x[source].numpy().reshape(1, -1), data.x[target].numpy().reshape(1, -1)) > 0.5:\n",
        "      BCG.add_edge(result_dict[source], result_dict[target])\n",
        "\n",
        "  num_nodes = BCG.number_of_nodes()\n",
        "  num_edges = BCG.number_of_edges()\n",
        "\n",
        "\n",
        "\n",
        "  print(\"Number of nodes:\", num_nodes)\n",
        "  print(\"Number of edges:\", num_edges)\n",
        "\n",
        "\n",
        "  return BCG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "id": "UHY6BTNs1rGj",
      "metadata": {
        "id": "UHY6BTNs1rGj"
      },
      "outputs": [],
      "source": [
        "from torch_geometric.data import Data\n",
        "\n",
        "def Sparisified_G_Alpha(BCG, data, list_of_tuples):\n",
        "  num_nodes = BCG.number_of_nodes()\n",
        "  new_x = torch.zeros(num_nodes,data.x.shape[1])\n",
        "  new_y = torch.zeros(num_nodes)\n",
        "  for i in range(len(list_of_tuples)):\n",
        "    new_x[i,:] = torch.mean(data.x[list(list_of_tuples[i]),:], axis = 0)\n",
        "    # new_x[i,:] = torch.sum(data.x[list(list_of_tuples[i]),:], axis = 0)\n",
        "    # new_x[i, :] = torch.tensor(np.median(data.x[list(list_of_tuples[i]), :], axis=0))\n",
        "    # new_x[i, :] = torch.max(data.x[list(list_of_tuples[i]), :], axis=0).values\n",
        "    # new_x[i, :] = torch.min(data.x[list(list_of_tuples[i]), :], axis=0).values\n",
        "\n",
        "\n",
        "    EC = list_of_tuples[i]\n",
        "    L = []\n",
        "    for ele in EC:\n",
        "      L.append(int(data.y[ele].numpy()))\n",
        "\n",
        "    keys = list(Counter(L).keys())\n",
        "    frequencies = list(Counter(L).values())\n",
        "\n",
        "    # Randomly select a key based on frequencies\n",
        "    random_key = random.choices(keys, frequencies)[0]\n",
        "    new_y[i] = int(random_key)\n",
        "\n",
        "  print(\"Completed_Flag\")\n",
        "  edges = list(BCG.edges())\n",
        "\n",
        "  # Create a dictionary to map node labels to integer indices\n",
        "  node_mapping = {node: index for index, node in enumerate(BCG.nodes())}\n",
        "\n",
        "  # Convert the edges to indices using the node_mapping\n",
        "  new_edge_index = [[node_mapping[source], node_mapping[target]] for source, target in edges]\n",
        "  new_edge_index = torch.tensor(new_edge_index, dtype=torch.long).t().contiguous()\n",
        "\n",
        "  data_new1 = Data()\n",
        "  data_new1.x = new_x\n",
        "  data_new1.y = new_y.long()\n",
        "  data_new1.edge_index = new_edge_index\n",
        "  data_new1.num_nodes = len(new_y)\n",
        "\n",
        "  return data_new1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "id": "IpO5YXs21rJ_",
      "metadata": {
        "id": "IpO5YXs21rJ_"
      },
      "outputs": [],
      "source": [
        "def Sparisified_G_Alpha_0(G, data):\n",
        "\n",
        "  new_x = torch.zeros(len(list(G.nodes)),data.x.shape[1])\n",
        "  new_y = torch.zeros(len(list(G.nodes)))\n",
        "  list_itr = list(G.nodes)\n",
        "  for i in range(len(list(G.nodes))):\n",
        "    new_x[i,:] = data.x[list_itr[i],:]\n",
        "    new_y[i] = int(data.y[list_itr[i]])\n",
        "\n",
        "  edges = list(G.edges())\n",
        "\n",
        "  # Create a dictionary to map node labels to integer indices\n",
        "  node_mapping = {node: index for index, node in enumerate(G.nodes())}\n",
        "\n",
        "  # Convert the edges to indices using the node_mapping\n",
        "  new_edge_index = [[node_mapping[source], node_mapping[target]] for source, target in edges]\n",
        "  new_edge_index = torch.tensor(new_edge_index, dtype=torch.long).t().contiguous()\n",
        "\n",
        "\n",
        "  data_new1 = Data()\n",
        "  data_new1.x = new_x\n",
        "  data_new1.y = new_y.long()\n",
        "  data_new1.edge_index = new_edge_index\n",
        "  data_new1.num_nodes = len(new_y)\n",
        "\n",
        "  return data_new1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "id": "vRTTcv8C1rNU",
      "metadata": {
        "id": "vRTTcv8C1rNU"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "id": "lF0vKaUR1rQe",
      "metadata": {
        "id": "lF0vKaUR1rQe"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "id": "OI7xOdM_x70O",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OI7xOdM_x70O",
        "outputId": "8ec37333-4f02-4d93-a381-a168467e1ea0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Execution time: 0.1646888256072998 seconds\n",
            "0.1\n",
            "Number of nodes: 581\n",
            "Number of edges: 416\n",
            "Completed_Flag\n",
            "Execution time of  (alpha, r) SPGC: 0.2444899082183838 seconds\n",
            "Number of nodes: 581\n",
            "Number of edges: 416\n",
            "Completed_Flag\n",
            "Execution time of SPGC: 0.1902916431427002 seconds\n"
          ]
        }
      ],
      "source": [
        "import copy\n",
        "from collections import Counter\n",
        "alpha_list = [0, 0.1, 1]\n",
        "\n",
        "for alpha in alpha_list:\n",
        "  # print(alpha)\n",
        "  if alpha == 0:\n",
        "    start_time = time.time()\n",
        "    data_new_1 = Sparisified_G_Alpha_0(G, cora)\n",
        "    end_time = time.time()\n",
        "    execution_time_SPGS = end_time - start_time\n",
        "    print(f\"Execution time: {execution_time_SPGS} seconds\")\n",
        "\n",
        "    tested_elements_set = set(tested_elements)\n",
        "    indices = [index for index, node in enumerate(G.nodes) if node in tested_elements_set]\n",
        "\n",
        "\n",
        "  if alpha > 0 and alpha < 1:\n",
        "    print(alpha)\n",
        "    if alpha == alpha_list[1]:\n",
        "      start_time_1 = time.time()\n",
        "      list_of_lists, indices = exclude_tested_elements_from_MB(partition, tested_elements)\n",
        "\n",
        "\n",
        "    list_of_tuples, result_dict = alpha_Sparsification(list_of_lists, cora, alpha)\n",
        "    # end_time_1 = time.time()\n",
        "    # execution_time_1 = end_time_1 - start_time_1\n",
        "    # print(f\"Execution time of alpha_Sparsification: {execution_time_1} seconds\")\n",
        "\n",
        "    BCG = Sparisified_G_NX(list_of_tuples, result_dict, cora)\n",
        "    data_new_1 = Sparisified_G_Alpha(BCG, cora, list_of_tuples)\n",
        "    end_time_2 = time.time()\n",
        "    execution_time_2 = end_time_2 - start_time_1\n",
        "    print(f\"Execution time of  (alpha, r) SPGC: {execution_time_2} seconds\")\n",
        "\n",
        "  if alpha == 1:\n",
        "    l_o_t = [tuple(inner_list) for inner_list in list_of_lists]\n",
        "    r_d = {element: index for index, tup in enumerate(list_of_tuples) for element in tup}\n",
        "    start_time_3 = time.time()\n",
        "    BCG = Sparisified_G_NX(l_o_t, r_d, cora)\n",
        "    data_new_1 = Sparisified_G_Alpha(BCG, cora, l_o_t)\n",
        "    end_time_3 = time.time()\n",
        "    execution_time_3 = end_time_3 - start_time_3\n",
        "    print(f\"Execution time of SPGC: {execution_time_3} seconds\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "id": "34b6f9a3-7a14-4a45-adb7-3f62aa7fee55",
      "metadata": {
        "id": "34b6f9a3-7a14-4a45-adb7-3f62aa7fee55"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "id": "972f25eb-c201-4ee5-a623-30a70d98e07c",
      "metadata": {
        "id": "972f25eb-c201-4ee5-a623-30a70d98e07c"
      },
      "outputs": [],
      "source": [
        "# from torch_geometric.nn import GATConv, GCNConv, GraphSAGE, BatchNorm\n",
        "# import torch\n",
        "\n",
        "# class GCN(torch.nn.Module):\n",
        "#   def __init__(self):\n",
        "#     super().__init__()\n",
        "\n",
        "#     self.conv1 = GCNConv(dataset.num_node_features, 128,aggr = 'mean')\n",
        "#     self.bc1 = BatchNorm(128)\n",
        "#     self.conv2 = GCNConv(128, 128,aggr = 'mean')\n",
        "#     self.bc2 = BatchNorm(128)\n",
        "#     self.conv3 = GCNConv(128, dataset.num_classes,aggr = 'mean')\n",
        "#     self.bc3 = BatchNorm(dataset.num_classes)\n",
        "#   def forward(self, x, edge_index):\n",
        "#     # x: Node feature matrix\n",
        "#     # edge_index: Graph connectivity matrix\n",
        "#     x = self.conv1(x, edge_index)\n",
        "#     x = torch.nn.functional.relu(x)\n",
        "#     x = self.bc1(x)\n",
        "#     x = self.conv2(x, edge_index)\n",
        "#     x = torch.nn.functional.relu(x)\n",
        "#     x = self.bc2(x)\n",
        "#     x = self.conv3(x, edge_index)\n",
        "#     x = torch.nn.functional.relu(x)\n",
        "#     x = self.bc3(x)\n",
        "#     return torch.nn.functional.log_softmax(x, dim=1)\n",
        "\n",
        "# model = GCN()\n",
        "# optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "# print(\"Graph Convolutional Network (GCN):\")\n",
        "# GCN()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "F1AmYE3OmYh_",
      "metadata": {
        "id": "F1AmYE3OmYh_"
      },
      "source": [
        "# 4-layer GCN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "id": "H-X2hJmAmYsb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H-X2hJmAmYsb",
        "outputId": "b88264e3-1411-4b4b-b240-a8216fc39d89"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Graph Convolutional Network (GCN):\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GCN(\n",
              "  (conv1): GCNConv(1433, 128)\n",
              "  (bc1): BatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (conv2): GCNConv(128, 128)\n",
              "  (bc2): BatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (conv3): GCNConv(128, 128)\n",
              "  (bc3): BatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (conv4): GCNConv(128, 7)\n",
              "  (bc4): BatchNorm(7, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ],
      "source": [
        "from torch_geometric.nn import GATConv, GCNConv, GraphSAGE, BatchNorm\n",
        "import torch\n",
        "\n",
        "class GCN(torch.nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "    self.conv1 = GCNConv(dataset.num_node_features, 128)\n",
        "    self.bc1 = BatchNorm(128)\n",
        "    self.conv2 = GCNConv(128, 128)\n",
        "    self.bc2 = BatchNorm(128)\n",
        "    self.conv3 = GCNConv(128, 128)\n",
        "    self.bc3 = BatchNorm(128)\n",
        "    self.conv4 = GCNConv(128, dataset.num_classes)\n",
        "    self.bc4 = BatchNorm(dataset.num_classes)\n",
        "    # self.dropout = Dropout(p=0.5)\n",
        "  def forward(self, x, edge_index):\n",
        "    # x: Node feature matrix\n",
        "    # edge_index: Graph connectivity matrix\n",
        "    x = self.conv1(x, edge_index)\n",
        "    x = torch.nn.functional.relu(x)\n",
        "    x = self.bc1(x)\n",
        "    x = self.conv2(x, edge_index)\n",
        "    x = torch.nn.functional.relu(x)\n",
        "    x = self.bc2(x)\n",
        "    x = self.conv3(x, edge_index)\n",
        "    x = torch.nn.functional.relu(x)\n",
        "    x = self.bc3(x)\n",
        "    x = self.conv4(x, edge_index)\n",
        "    x = torch.nn.functional.relu(x)\n",
        "    x = self.bc4(x)\n",
        "\n",
        "    return torch.nn.functional.log_softmax(x, dim=1)\n",
        "\n",
        "model = GCN()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "print(\"Graph Convolutional Network (GCN):\")\n",
        "GCN()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "XgSWA0AWgB8b",
      "metadata": {
        "id": "XgSWA0AWgB8b"
      },
      "source": [
        "# 3 Layer GCN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "id": "LpGIE6-x9fog",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LpGIE6-x9fog",
        "outputId": "c71c93ea-8da7-4bd9-a179-36de178901e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Graph Convolutional Network (GCN):\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GCN(\n",
              "  (conv1): GCNConv(1433, 128)\n",
              "  (bc1): BatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (conv2): GCNConv(128, 128)\n",
              "  (bc2): BatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (conv3): GCNConv(128, 7)\n",
              "  (bc3): BatchNorm(7, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 100
        }
      ],
      "source": [
        "from torch_geometric.nn import GATConv, GCNConv, GraphSAGE, BatchNorm\n",
        "import torch\n",
        "\n",
        "class GCN(torch.nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "    self.conv1 = GCNConv(dataset.num_node_features, 128)\n",
        "    self.bc1 = BatchNorm(128)\n",
        "    self.conv2 = GCNConv(128, 128)\n",
        "    self.bc2 = BatchNorm(128)\n",
        "    self.conv3 = GCNConv(128, dataset.num_classes)\n",
        "    self.bc3 = BatchNorm(dataset.num_classes)\n",
        "    # self.dropout = Dropout(p=0.5)\n",
        "  def forward(self, x, edge_index):\n",
        "    # x: Node feature matrix\n",
        "    # edge_index: Graph connectivity matrix\n",
        "    x = self.conv1(x, edge_index)\n",
        "    x = torch.nn.functional.relu(x)\n",
        "    x = self.bc1(x)\n",
        "    # x = self.dropout(x)\n",
        "    x = self.conv2(x, edge_index)\n",
        "    x = torch.nn.functional.relu(x)\n",
        "    x = self.bc2(x)\n",
        "    # x = self.dropout(x)\n",
        "    x = self.conv3(x, edge_index)\n",
        "    x = torch.nn.functional.relu(x)\n",
        "    x = self.bc3(x)\n",
        "    return torch.nn.functional.log_softmax(x, dim=1)\n",
        "\n",
        "model = GCN()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "print(\"Graph Convolutional Network (GCN):\")\n",
        "GCN()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "q9RKQyEEgElZ",
      "metadata": {
        "id": "q9RKQyEEgElZ"
      },
      "source": [
        "# 2-layer GCN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "id": "bYheu2KlgECS",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bYheu2KlgECS",
        "outputId": "a36c113d-c82a-4e84-c1bd-ea504304ed9b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Graph Convolutional Network (GCN):\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GCN(\n",
              "  (conv1): GCNConv(1433, 128)\n",
              "  (bc1): BatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (conv2): GCNConv(128, 7)\n",
              "  (bc2): BatchNorm(7, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ],
      "source": [
        "from torch_geometric.nn import GATConv, GCNConv, GraphSAGE, BatchNorm\n",
        "import torch\n",
        "\n",
        "class GCN(torch.nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "    self.conv1 = GCNConv(dataset.num_node_features, 128)\n",
        "    self.bc1 = BatchNorm(128)\n",
        "    self.conv2 = GCNConv(128, 7)\n",
        "    self.bc2 = BatchNorm(dataset.num_classes)\n",
        "\n",
        "  def forward(self, x, edge_index):\n",
        "    # x: Node feature matrix\n",
        "    # edge_index: Graph connectivity matrix\n",
        "    x = self.conv1(x, edge_index)\n",
        "    x = torch.nn.functional.relu(x)\n",
        "    x = self.bc1(x)\n",
        "    x = self.conv2(x, edge_index)\n",
        "    x = torch.nn.functional.relu(x)\n",
        "    x = self.bc2(x)\n",
        "\n",
        "    return torch.nn.functional.log_softmax(x, dim=1)\n",
        "\n",
        "model = GCN()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "print(\"Graph Convolutional Network (GCN):\")\n",
        "GCN()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Qu-s0i2Gmuqy",
      "metadata": {
        "id": "Qu-s0i2Gmuqy"
      },
      "source": [
        "# 4-layer GAT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "id": "Ckt2BooemuyX",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ckt2BooemuyX",
        "outputId": "c59dc332-a1e6-44f5-9709-cf7cb013e7e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GAT:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GAT(\n",
              "  (conv1): GATConv(1433, 128, heads=1)\n",
              "  (bc1): BatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (conv2): GATConv(128, 128, heads=1)\n",
              "  (bc2): BatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (conv3): GATConv(128, 128, heads=1)\n",
              "  (bc3): BatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (conv4): GATConv(128, 7, heads=1)\n",
              "  (bc4): BatchNorm(7, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ],
      "source": [
        "from torch_geometric.nn import GATConv, GCNConv, SAGEConv\n",
        "import torch\n",
        "\n",
        "class GAT(torch.nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.conv1 = GATConv(dataset.num_node_features, 128)\n",
        "    self.bc1 = BatchNorm(128)\n",
        "    self.conv2 = GATConv(128, 128)\n",
        "    self.bc2 = BatchNorm(128)\n",
        "    self.conv3 = GATConv(128, 128)\n",
        "    self.bc3 = BatchNorm(128)\n",
        "    self.conv4 = GATConv(128, dataset.num_classes)\n",
        "    self.bc4 = BatchNorm(dataset.num_classes)\n",
        "\n",
        "  def forward(self, x, edge_index):\n",
        "    # x: Node feature matrix\n",
        "    # edge_index: Graph connectivity matrix\n",
        "    x = self.conv1(x, edge_index)\n",
        "    x = torch.nn.functional.relu(x)\n",
        "    x = self.bc1(x)\n",
        "    # x = self.dropout(x)\n",
        "    x = self.conv2(x, edge_index)\n",
        "    x = torch.nn.functional.relu(x)\n",
        "    x = self.bc2(x)\n",
        "    # x = self.dropout(x)\n",
        "    x = self.conv3(x, edge_index)\n",
        "    x = torch.nn.functional.relu(x)\n",
        "    x = self.bc3(x)\n",
        "    x = self.conv4(x, edge_index)\n",
        "    x = torch.nn.functional.relu(x)\n",
        "    x = self.bc4(x)\n",
        "\n",
        "    return torch.nn.functional.log_softmax(x, dim=1)\n",
        "\n",
        "model = GAT()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "print(\"GAT:\")\n",
        "GAT()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "mCaulAMzgTNx",
      "metadata": {
        "id": "mCaulAMzgTNx"
      },
      "source": [
        "# 3-layer GAT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "id": "723BnBCM9qY8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "723BnBCM9qY8",
        "outputId": "5fcd713d-6c41-4156-cce4-52d2f0bfc156"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GAT:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GAT(\n",
              "  (conv1): GATConv(1433, 128, heads=1)\n",
              "  (bc1): BatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (conv2): GATConv(128, 128, heads=1)\n",
              "  (bc2): BatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (conv3): GATConv(128, 7, heads=1)\n",
              "  (bc3): BatchNorm(7, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ],
      "source": [
        "from torch_geometric.nn import GATConv, GCNConv, SAGEConv\n",
        "import torch\n",
        "\n",
        "class GAT(torch.nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.conv1 = GATConv(dataset.num_node_features, 128)\n",
        "    self.bc1 = BatchNorm(128)\n",
        "    self.conv2 = GATConv(128, 128)\n",
        "    self.bc2 = BatchNorm(128)\n",
        "    self.conv3 = GATConv(128, dataset.num_classes)\n",
        "    self.bc3 = BatchNorm(dataset.num_classes)\n",
        "    # self.dropout = Dropout(p=0.5)\n",
        "\n",
        "  def forward(self, x, edge_index):\n",
        "    # x: Node feature matrix\n",
        "    # edge_index: Graph connectivity matrix\n",
        "    x = self.conv1(x, edge_index)\n",
        "    x = torch.nn.functional.relu(x)\n",
        "    x = self.bc1(x)\n",
        "    # x = self.dropout(x)\n",
        "    x = self.conv2(x, edge_index)\n",
        "    x = torch.nn.functional.relu(x)\n",
        "    x = self.bc2(x)\n",
        "    # x = self.dropout(x)\n",
        "    x = self.conv3(x, edge_index)\n",
        "    x = torch.nn.functional.relu(x)\n",
        "    x = self.bc3(x)\n",
        "    return torch.nn.functional.log_softmax(x, dim=1)\n",
        "\n",
        "model = GAT()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "print(\"GAT:\")\n",
        "GAT()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aSJLBCkGgVg6",
      "metadata": {
        "id": "aSJLBCkGgVg6"
      },
      "source": [
        "# 2-layer GAT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "id": "VXtFxRUmgVp1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VXtFxRUmgVp1",
        "outputId": "1b642069-a109-4204-a4a1-f82570878a33"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GAT:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GAT(\n",
              "  (conv1): GATConv(1433, 128, heads=1)\n",
              "  (bc1): BatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (conv2): GATConv(128, 7, heads=1)\n",
              "  (bc2): BatchNorm(7, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 104
        }
      ],
      "source": [
        "from torch_geometric.nn import GATConv, GCNConv, SAGEConv\n",
        "import torch\n",
        "\n",
        "class GAT(torch.nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.conv1 = GATConv(dataset.num_node_features, 128)\n",
        "    self.bc1 = BatchNorm(128)\n",
        "    self.conv2 = GATConv(128, 7)\n",
        "    self.bc2 = BatchNorm(dataset.num_classes)\n",
        "\n",
        "  def forward(self, x, edge_index):\n",
        "    # x: Node feature matrix\n",
        "    # edge_index: Graph connectivity matrix\n",
        "    x = self.conv1(x, edge_index)\n",
        "    x = torch.nn.functional.relu(x)\n",
        "    x = self.bc1(x)\n",
        "    # x = self.dropout(x)\n",
        "    x = self.conv2(x, edge_index)\n",
        "    x = torch.nn.functional.relu(x)\n",
        "    x = self.bc2(x)\n",
        "    return torch.nn.functional.log_softmax(x, dim=1)\n",
        "\n",
        "model = GAT()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "print(\"GAT:\")\n",
        "GAT()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "CCu-Rogjm9hf",
      "metadata": {
        "id": "CCu-Rogjm9hf"
      },
      "source": [
        "# 4-layer SAGE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "id": "DxwzaWgTm9pj",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DxwzaWgTm9pj",
        "outputId": "a1c7f01b-4c74-4ad6-ef7d-b275f36f692e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GraphSAGE:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GraphSAGE(\n",
              "  (conv1): SAGEConv(1433, 128, aggr=mean)\n",
              "  (bc1): BatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (conv2): SAGEConv(128, 128, aggr=mean)\n",
              "  (bc2): BatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (conv3): SAGEConv(128, 128, aggr=mean)\n",
              "  (bc3): BatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (conv4): SAGEConv(128, 7, aggr=mean)\n",
              "  (bc4): BatchNorm(7, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 105
        }
      ],
      "source": [
        "from torch_geometric.nn import GATConv, GCNConv, SAGEConv\n",
        "import torch\n",
        "from torch.nn import Module, Dropout\n",
        "\n",
        "class GraphSAGE(torch.nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.conv1 = SAGEConv(dataset.num_node_features, 128)\n",
        "    self.bc1 = BatchNorm(128)\n",
        "    self.conv2 = SAGEConv(128, 128)\n",
        "    self.bc2 = BatchNorm(128)\n",
        "    self.conv3 = SAGEConv(128, 128)\n",
        "    self.bc3 = BatchNorm(128)\n",
        "    self.conv4 = SAGEConv(128, dataset.num_classes)\n",
        "    self.bc4 = BatchNorm(dataset.num_classes)\n",
        "    # self.dropout = Dropout(p=0.5)\n",
        "\n",
        "  def forward(self, x, edge_index):\n",
        "    # x: Node feature matrix\n",
        "    # edge_index: Graph connectivity matrix\n",
        "    x = self.conv1(x, edge_index)\n",
        "    x = torch.nn.functional.relu(x)\n",
        "    x = self.bc1(x)\n",
        "    # x = self.dropout(x)\n",
        "    x = self.conv2(x, edge_index)\n",
        "    x = torch.nn.functional.relu(x)\n",
        "    x = self.bc2(x)\n",
        "    # x = self.dropout(x)\n",
        "    x = self.conv3(x, edge_index)\n",
        "    x = torch.nn.functional.relu(x)\n",
        "    x = self.bc3(x)\n",
        "    x = self.conv4(x, edge_index)\n",
        "    x = torch.nn.functional.relu(x)\n",
        "    x = self.bc4(x)\n",
        "\n",
        "    return torch.nn.functional.log_softmax(x, dim=1)\n",
        "\n",
        "model = GraphSAGE()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "print(\"GraphSAGE:\")\n",
        "GraphSAGE()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ZbeE62gHgeFy",
      "metadata": {
        "id": "ZbeE62gHgeFy"
      },
      "source": [
        "# 3-layer SAGE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "id": "ddnC-sJ3PihA",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ddnC-sJ3PihA",
        "outputId": "a82ef31f-ce6a-4710-bc9a-b8b002ae4b75"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GraphSAGE:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GraphSAGE(\n",
              "  (conv1): SAGEConv(1433, 128, aggr=mean)\n",
              "  (bc1): BatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (conv2): SAGEConv(128, 128, aggr=mean)\n",
              "  (bc2): BatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (conv3): SAGEConv(128, 7, aggr=mean)\n",
              "  (bc3): BatchNorm(7, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ],
      "source": [
        "from torch_geometric.nn import GATConv, GCNConv, SAGEConv\n",
        "import torch\n",
        "from torch.nn import Module, Dropout\n",
        "\n",
        "class GraphSAGE(torch.nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.conv1 = SAGEConv(dataset.num_node_features, 128)\n",
        "    self.bc1 = BatchNorm(128)\n",
        "    self.conv2 = SAGEConv(128, 128)\n",
        "    self.bc2 = BatchNorm(128)\n",
        "    self.conv3 = SAGEConv(128, dataset.num_classes)\n",
        "    self.bc3 = BatchNorm(dataset.num_classes)\n",
        "    # self.dropout = Dropout(p=0.5)\n",
        "\n",
        "  def forward(self, x, edge_index):\n",
        "    # x: Node feature matrix\n",
        "    # edge_index: Graph connectivity matrix\n",
        "    x = self.conv1(x, edge_index)\n",
        "    x = torch.nn.functional.relu(x)\n",
        "    x = self.bc1(x)\n",
        "    # x = self.dropout(x)\n",
        "    x = self.conv2(x, edge_index)\n",
        "    x = torch.nn.functional.relu(x)\n",
        "    x = self.bc2(x)\n",
        "    # x = self.dropout(x)\n",
        "    x = self.conv3(x, edge_index)\n",
        "    x = torch.nn.functional.relu(x)\n",
        "    x = self.bc3(x)\n",
        "    return torch.nn.functional.log_softmax(x, dim=1)\n",
        "\n",
        "model = GraphSAGE()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "print(\"GraphSAGE:\")\n",
        "GraphSAGE()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1BwhMee5gf6c",
      "metadata": {
        "id": "1BwhMee5gf6c"
      },
      "source": [
        "# 2-layer SAGE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "id": "FWJyq5QSggGr",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FWJyq5QSggGr",
        "outputId": "a290cc7a-570b-4525-b618-61fe5b2988a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GraphSAGE:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GraphSAGE(\n",
              "  (conv1): SAGEConv(1433, 128, aggr=mean)\n",
              "  (bc1): BatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (conv2): SAGEConv(128, 7, aggr=mean)\n",
              "  (bc2): BatchNorm(7, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 107
        }
      ],
      "source": [
        "from torch_geometric.nn import GATConv, GCNConv, SAGEConv\n",
        "import torch\n",
        "from torch.nn import Module, Dropout\n",
        "\n",
        "class GraphSAGE(torch.nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.conv1 = SAGEConv(dataset.num_node_features, 128)\n",
        "    self.bc1 = BatchNorm(128)\n",
        "    self.conv2 = SAGEConv(128, 7)\n",
        "    self.bc2 = BatchNorm(dataset.num_classes)\n",
        "\n",
        "  def forward(self, x, edge_index):\n",
        "    # x: Node feature matrix\n",
        "    # edge_index: Graph connectivity matrix\n",
        "    x = self.conv1(x, edge_index)\n",
        "    x = torch.nn.functional.relu(x)\n",
        "    x = self.bc1(x)\n",
        "    x = self.conv2(x, edge_index)\n",
        "    x = torch.nn.functional.relu(x)\n",
        "    x = self.bc2(x)\n",
        "\n",
        "    return torch.nn.functional.log_softmax(x, dim=1)\n",
        "\n",
        "model = GraphSAGE()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "print(\"GraphSAGE:\")\n",
        "GraphSAGE()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "id": "d10e1e4b-85b2-4b77-bae5-181f8a9f9567",
      "metadata": {
        "id": "d10e1e4b-85b2-4b77-bae5-181f8a9f9567"
      },
      "outputs": [],
      "source": [
        "# from torch_geometric.nn import GATConv, GCNConv, SAGEConv\n",
        "# import torch\n",
        "\n",
        "# class GraphSAGE(torch.nn.Module):\n",
        "#   def __init__(self):\n",
        "#     super().__init__()\n",
        "#     self.conv1 = SAGEConv(dataset.num_node_features, 128)\n",
        "#     # self.conv2 = GCNConv(40, 20)\n",
        "#     self.conv2 = SAGEConv(128, dataset.num_classes)\n",
        "#   def forward(self, x, edge_index):\n",
        "#     # x: Node feature matrix\n",
        "#     # edge_index: Graph connectivity matri\n",
        "#     x = self.conv1(x, edge_index)\n",
        "#     x = torch.nn.functional.relu(x)\n",
        "#     x = self.conv2(x, edge_index)\n",
        "#     x = torch.nn.functional.relu(x)\n",
        "\n",
        "#     return torch.nn.functional.log_softmax(x, dim=1)\n",
        "\n",
        "# model = GraphSAGE()\n",
        "# optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
        "# print(\"GraphSAGE:\")\n",
        "# GraphSAGE()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "id": "b68b7aea-5862-454b-882c-045f89ce7f67",
      "metadata": {
        "id": "b68b7aea-5862-454b-882c-045f89ce7f67"
      },
      "outputs": [],
      "source": [
        "# from torch_geometric.nn import GATConv, GCNConv, SAGEConv\n",
        "# import torch\n",
        "\n",
        "# class GAT(torch.nn.Module):\n",
        "#   def __init__(self):\n",
        "#     super().__init__()\n",
        "#     self.conv1 = GATConv(dataset.num_node_features, 128,aggr = 'mean')\n",
        "#     self.bc1 = BatchNorm(128)\n",
        "#     self.conv2 = GATConv(128, 128,aggr = 'mean')\n",
        "#     self.bc2 = BatchNorm(128)\n",
        "#     self.conv3 = GATConv(128, dataset.num_classes,aggr = 'mean')\n",
        "#     self.bc3 = BatchNorm(dataset.num_classes)\n",
        "\n",
        "#   def forward(self, x, edge_index):\n",
        "#     # x: Node feature matrix\n",
        "#     # edge_index: Graph connectivity matrix\n",
        "#     x = self.conv1(x, edge_index)\n",
        "#     x = torch.nn.functional.relu(x)\n",
        "#     x = self.bc1(x)\n",
        "#     x = self.conv2(x, edge_index)\n",
        "#     x = torch.nn.functional.relu(x)\n",
        "#     x = self.bc2(x)\n",
        "#     x = self.conv3(x, edge_index)\n",
        "#     x = torch.nn.functional.relu(x)\n",
        "#     x = self.bc3(x)\n",
        "#     return torch.nn.functional.log_softmax(x, dim=1)\n",
        "\n",
        "# model = GAT()\n",
        "# optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
        "# print(\"GAT:\")\n",
        "# GAT()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "id": "dd322689-eb02-4a60-b2ec-fcab7a41ac26",
      "metadata": {
        "id": "dd322689-eb02-4a60-b2ec-fcab7a41ac26"
      },
      "outputs": [],
      "source": [
        "# from torch_geometric.nn import GraphSAGE, GATConv\n",
        "# import torch\n",
        "\n",
        "# class GAT(torch.nn.Module):\n",
        "#   def __init__(self):\n",
        "#     super().__init__()\n",
        "#     self.conv1 = GATConv(dataset.num_node_features, 80, aggr = 'mean')\n",
        "#     # self.conv2 = GCNConv(40, 20)\n",
        "#     self.conv2 = GATConv(80, dataset.num_classes, aggr = 'mean')\n",
        "#   def forward(self, x, edge_index):\n",
        "#     # x: Node feature matrix\n",
        "#     # edge_index: Graph connectivity matrix\n",
        "#     x = self.conv1(x, edge_index)\n",
        "#     x = torch.nn.functional.relu(x)\n",
        "#     # x = torch.nn.functional.dropout(x, training=self.training)\n",
        "#     x = self.conv2(x, edge_index)\n",
        "#     x = torch.nn.functional.relu(x)\n",
        "#     # x = self.conv3(x, edge_index)\n",
        "#     # x = torch.nn.functional.relu(x)\n",
        "#     # # x = self.conv4(x, edge_index)\n",
        "#     return torch.nn.functional.log_softmax(x, dim=1)\n",
        "\n",
        "# model = GAT()\n",
        "# optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
        "# print(\"Graph Attention Networks(GAT):\")\n",
        "# GAT()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_save_path_GCN = '/content/drive/MyDrive/GNN_Sparsification/gcn_model.pt'\n",
        "model_save_path_GAT = '/content/drive/MyDrive/GNN_Sparsification/gat_model.pt'\n",
        "model_save_path_GraphSage = '/content/drive/MyDrive/GNN_Sparsification/graphsage_model.pt'\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "fFjfRuQYjxD8"
      },
      "id": "fFjfRuQYjxD8",
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "zcUPYHBbJqRy",
      "metadata": {
        "id": "zcUPYHBbJqRy"
      },
      "source": [
        "# Pre-trained GCN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "id": "pln6HEAJzjbP",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pln6HEAJzjbP",
        "outputId": "ae23160c-fdf0-429e-b0aa-13a5e2e38170"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 10, Loss: 0.0255, Training Acc: 0.9967\n",
            "Epoch: 20, Loss: 0.0126, Training Acc: 0.9974\n",
            "Epoch: 30, Loss: 0.0098, Training Acc: 0.9974\n",
            "Epoch: 40, Loss: 0.0088, Training Acc: 0.9974\n",
            "Epoch: 50, Loss: 0.0083, Training Acc: 0.9974\n",
            "Epoch: 60, Loss: 0.0080, Training Acc: 0.9974\n",
            "Epoch: 70, Loss: 0.0078, Training Acc: 0.9974\n",
            "Epoch: 80, Loss: 0.0077, Training Acc: 0.9974\n",
            "Epoch: 90, Loss: 0.0076, Training Acc: 0.9974\n",
            "Epoch: 100, Loss: 0.0075, Training Acc: 0.9974\n",
            "Epoch: 110, Loss: 0.0075, Training Acc: 0.9974\n",
            "Epoch: 120, Loss: 0.0074, Training Acc: 0.9974\n",
            "Epoch: 130, Loss: 0.0074, Training Acc: 0.9974\n",
            "Epoch: 140, Loss: 0.0073, Training Acc: 0.9974\n",
            "Epoch: 150, Loss: 0.0073, Training Acc: 0.9974\n",
            "Epoch: 160, Loss: 0.0072, Training Acc: 0.9974\n",
            "Epoch: 170, Loss: 0.0072, Training Acc: 0.9974\n",
            "Epoch: 180, Loss: 0.0072, Training Acc: 0.9974\n",
            "Epoch: 190, Loss: 0.0072, Training Acc: 0.9974\n",
            "Epoch: 200, Loss: 0.0071, Training Acc: 0.9974\n",
            "Epoch: 210, Loss: 0.0071, Training Acc: 0.9974\n",
            "Epoch: 220, Loss: 0.0071, Training Acc: 0.9974\n",
            "Epoch: 230, Loss: 0.0071, Training Acc: 0.9974\n",
            "Epoch: 240, Loss: 0.0070, Training Acc: 0.9974\n",
            "Epoch: 250, Loss: 0.0070, Training Acc: 0.9974\n",
            "Epoch: 260, Loss: 0.0070, Training Acc: 0.9974\n",
            "Epoch: 270, Loss: 0.0070, Training Acc: 0.9974\n",
            "Epoch: 280, Loss: 0.0070, Training Acc: 0.9974\n",
            "Epoch: 290, Loss: 0.0070, Training Acc: 0.9974\n",
            "Epoch: 300, Loss: 0.0069, Training Acc: 0.9974\n",
            "Training time: 36.75463008880615 seconds\n"
          ]
        }
      ],
      "source": [
        "# train the model\n",
        "def compute_accuracy(pred_y, y):\n",
        "    return (pred_y == y).sum()\n",
        "\n",
        "import time\n",
        "\n",
        "# Start recording the current time\n",
        "start_time = time.time()\n",
        "\n",
        "\n",
        "model.train()\n",
        "losses = []\n",
        "accuracies = []\n",
        "for epoch in range(300):\n",
        "  optimizer.zero_grad()\n",
        "  out = model(cora.x, cora.edge_index)\n",
        "  loss = torch.nn.functional.nll_loss(out, cora.y)\n",
        "  correct = compute_accuracy(out.argmax(dim=1), cora.y)\n",
        "  acc = int(correct) / len(cora.y)\n",
        "  losses.append(loss.item())\n",
        "  accuracies.append(acc)\n",
        "\n",
        "  # torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
        "\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "  if (epoch+1) % 10 == 0:\n",
        "    print('Epoch: {}, Loss: {:.4f}, Training Acc: {:.4f}'.format(epoch+1, loss.item(), acc))\n",
        "\n",
        "# End recording the current time\n",
        "end_time = time.time()\n",
        "\n",
        "# Calculate the elapsed time\n",
        "elapsed_time = end_time - start_time\n",
        "\n",
        "print(\"Training time:\", elapsed_time, \"seconds\")\n",
        "\n",
        "torch.save(model.state_dict(), model_save_path_GCN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "id": "0_oMMVoIij_p",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0_oMMVoIij_p",
        "outputId": "3bd1d473-a124-4aac-82d2-eaec5e8fbdd2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-5.6217, -5.9382, -5.5477,  ..., -5.4687, -5.8939, -5.8177],\n",
              "        [-6.1768, -6.4933, -6.1028,  ..., -0.0132, -6.4490, -6.3728],\n",
              "        [-6.1798, -6.4963, -6.1059,  ..., -0.0131, -6.4520, -6.3759],\n",
              "        ...,\n",
              "        [-5.6187, -5.9352, -5.5448,  ..., -5.4657, -5.8909, -5.8148],\n",
              "        [-5.6134, -5.9299, -5.5395,  ..., -5.4605, -5.8856, -5.8095],\n",
              "        [-5.6140, -5.9305, -5.5400,  ..., -5.4610, -5.8862, -5.8100]],\n",
              "       grad_fn=<LogSoftmaxBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 112
        }
      ],
      "source": [
        "out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "id": "3d14314f-5868-4f8b-b7ac-74f33c4f8c34",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3d14314f-5868-4f8b-b7ac-74f33c4f8c34",
        "outputId": "d086cfdb-6ca9-4999-f507-3638391d0a7a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 10, Loss: 0.0261, Training Acc: 0.9930\n",
            "Epoch: 20, Loss: 0.0238, Training Acc: 0.9930\n",
            "Epoch: 30, Loss: 0.0225, Training Acc: 0.9930\n",
            "Epoch: 40, Loss: 0.0217, Training Acc: 0.9930\n",
            "Epoch: 50, Loss: 0.0212, Training Acc: 0.9930\n",
            "Epoch: 60, Loss: 0.0209, Training Acc: 0.9930\n",
            "Epoch: 70, Loss: 0.0206, Training Acc: 0.9930\n",
            "Epoch: 80, Loss: 0.0204, Training Acc: 0.9930\n",
            "Epoch: 90, Loss: 0.0202, Training Acc: 0.9930\n",
            "Epoch: 100, Loss: 0.0200, Training Acc: 0.9930\n",
            "Epoch: 110, Loss: 0.0198, Training Acc: 0.9930\n",
            "Epoch: 120, Loss: 0.0196, Training Acc: 0.9930\n",
            "Epoch: 130, Loss: 0.0195, Training Acc: 0.9930\n",
            "Epoch: 140, Loss: 0.0193, Training Acc: 0.9930\n",
            "Epoch: 150, Loss: 0.0192, Training Acc: 0.9930\n",
            "Epoch: 160, Loss: 0.0191, Training Acc: 0.9930\n",
            "Epoch: 170, Loss: 0.0189, Training Acc: 0.9930\n",
            "Epoch: 180, Loss: 0.0188, Training Acc: 0.9930\n",
            "Epoch: 190, Loss: 0.0187, Training Acc: 0.9930\n",
            "Epoch: 200, Loss: 0.0186, Training Acc: 0.9930\n",
            "Epoch: 210, Loss: 0.0184, Training Acc: 0.9930\n",
            "Epoch: 220, Loss: 0.0183, Training Acc: 0.9930\n",
            "Epoch: 230, Loss: 0.0182, Training Acc: 0.9930\n",
            "Epoch: 240, Loss: 0.0181, Training Acc: 0.9930\n",
            "Epoch: 250, Loss: 0.0180, Training Acc: 0.9930\n",
            "Epoch: 260, Loss: 0.0179, Training Acc: 0.9930\n",
            "Epoch: 270, Loss: 0.0178, Training Acc: 0.9930\n",
            "Epoch: 280, Loss: 0.0177, Training Acc: 0.9930\n",
            "Epoch: 290, Loss: 0.0176, Training Acc: 0.9930\n",
            "Epoch: 300, Loss: 0.0175, Training Acc: 0.9930\n",
            "Training time: 34.911678075790405 seconds\n"
          ]
        }
      ],
      "source": [
        "# train the model\n",
        "def compute_accuracy(pred_y, y):\n",
        "    return (pred_y == y).sum()\n",
        "\n",
        "import time\n",
        "\n",
        "# Start recording the current time\n",
        "start_time = time.time()\n",
        "\n",
        "\n",
        "model.train()\n",
        "losses = []\n",
        "accuracies = []\n",
        "for epoch in range(300):\n",
        "  optimizer.zero_grad()\n",
        "  out = model(cora.x, cora.edge_index)\n",
        "  loss = torch.nn.functional.nll_loss(out[~test_mask], cora.y[~test_mask])\n",
        "  correct = compute_accuracy(out[~test_mask].argmax(dim=1), cora.y[~test_mask])\n",
        "  acc = int(correct) / (len(test_mask)-int(test_mask.int().sum()))\n",
        "  losses.append(loss.item())\n",
        "  accuracies.append(acc)\n",
        "\n",
        "  # torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
        "\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "  if (epoch+1) % 10 == 0:\n",
        "    print('Epoch: {}, Loss: {:.4f}, Training Acc: {:.4f}'.format(epoch+1, loss.item(), acc))\n",
        "\n",
        "# End recording the current time\n",
        "end_time = time.time()\n",
        "\n",
        "# Calculate the elapsed time\n",
        "elapsed_time = end_time - start_time\n",
        "\n",
        "print(\"Training time:\", elapsed_time, \"seconds\")\n",
        "\n",
        "# torch.save(model.state_dict(), model_save_path_GCN)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "UQef0R0IJvpN",
      "metadata": {
        "id": "UQef0R0IJvpN"
      },
      "source": [
        "# Pre-trained GAT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "id": "RLW_7f_IFO4x",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RLW_7f_IFO4x",
        "outputId": "9fc05587-ffa0-479a-c7fb-f1984af14129"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 10, Loss: 0.0138, Training Acc: 0.9948\n",
            "Epoch: 20, Loss: 0.0138, Training Acc: 0.9948\n",
            "Epoch: 30, Loss: 0.0138, Training Acc: 0.9948\n",
            "Epoch: 40, Loss: 0.0137, Training Acc: 0.9948\n",
            "Epoch: 50, Loss: 0.0137, Training Acc: 0.9948\n",
            "Epoch: 60, Loss: 0.0137, Training Acc: 0.9948\n",
            "Epoch: 70, Loss: 0.0137, Training Acc: 0.9948\n",
            "Epoch: 80, Loss: 0.0137, Training Acc: 0.9948\n",
            "Epoch: 90, Loss: 0.0136, Training Acc: 0.9948\n",
            "Epoch: 100, Loss: 0.0136, Training Acc: 0.9948\n",
            "Epoch: 110, Loss: 0.0136, Training Acc: 0.9948\n",
            "Epoch: 120, Loss: 0.0136, Training Acc: 0.9948\n",
            "Epoch: 130, Loss: 0.0136, Training Acc: 0.9948\n",
            "Epoch: 140, Loss: 0.0136, Training Acc: 0.9948\n",
            "Epoch: 150, Loss: 0.0135, Training Acc: 0.9948\n",
            "Epoch: 160, Loss: 0.0135, Training Acc: 0.9948\n",
            "Epoch: 170, Loss: 0.0135, Training Acc: 0.9948\n",
            "Epoch: 180, Loss: 0.0135, Training Acc: 0.9948\n",
            "Epoch: 190, Loss: 0.0135, Training Acc: 0.9948\n",
            "Epoch: 200, Loss: 0.0135, Training Acc: 0.9948\n",
            "Epoch: 210, Loss: 0.0135, Training Acc: 0.9948\n",
            "Epoch: 220, Loss: 0.0134, Training Acc: 0.9948\n",
            "Epoch: 230, Loss: 0.0134, Training Acc: 0.9948\n",
            "Epoch: 240, Loss: 0.0134, Training Acc: 0.9948\n",
            "Epoch: 250, Loss: 0.0134, Training Acc: 0.9948\n",
            "Epoch: 260, Loss: 0.0134, Training Acc: 0.9948\n",
            "Epoch: 270, Loss: 0.0134, Training Acc: 0.9948\n",
            "Epoch: 280, Loss: 0.0134, Training Acc: 0.9948\n",
            "Epoch: 290, Loss: 0.0134, Training Acc: 0.9948\n",
            "Epoch: 300, Loss: 0.0133, Training Acc: 0.9948\n",
            "Training time: 34.52083683013916 seconds\n"
          ]
        }
      ],
      "source": [
        "# train the model\n",
        "def compute_accuracy(pred_y, y):\n",
        "    return (pred_y == y).sum()\n",
        "\n",
        "import time\n",
        "\n",
        "# Start recording the current time\n",
        "start_time = time.time()\n",
        "\n",
        "\n",
        "model.train()\n",
        "losses = []\n",
        "accuracies = []\n",
        "for epoch in range(300):\n",
        "  optimizer.zero_grad()\n",
        "  out = model(cora.x, cora.edge_index)\n",
        "  loss = torch.nn.functional.nll_loss(out[~test_mask], data.y[~test_mask])\n",
        "  correct = compute_accuracy(out[~test_mask].argmax(dim=1), data.y[~test_mask])\n",
        "  acc = int(correct) / (len(test_mask)-int(test_mask.int().sum()))\n",
        "  losses.append(loss.item())\n",
        "  accuracies.append(acc)\n",
        "\n",
        "  # torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
        "\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "  if (epoch+1) % 10 == 0:\n",
        "    print('Epoch: {}, Loss: {:.4f}, Training Acc: {:.4f}'.format(epoch+1, loss.item(), acc))\n",
        "\n",
        "# End recording the current time\n",
        "end_time = time.time()\n",
        "\n",
        "# Calculate the elapsed time\n",
        "elapsed_time = end_time - start_time\n",
        "\n",
        "print(\"Training time:\", elapsed_time, \"seconds\")\n",
        "\n",
        "torch.save(model.state_dict(), model_save_path_GAT)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "QGBP_RltJyOU",
      "metadata": {
        "id": "QGBP_RltJyOU"
      },
      "source": [
        "# Pre-trained GraphSage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "id": "QdJPAtH6FPYA",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QdJPAtH6FPYA",
        "outputId": "c60e90a9-fe0f-485c-950f-5e0433626c5c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 10, Loss: 0.0129, Training Acc: 0.9948\n",
            "Epoch: 20, Loss: 0.0128, Training Acc: 0.9948\n",
            "Epoch: 30, Loss: 0.0128, Training Acc: 0.9948\n",
            "Epoch: 40, Loss: 0.0128, Training Acc: 0.9948\n",
            "Epoch: 50, Loss: 0.0128, Training Acc: 0.9948\n",
            "Epoch: 60, Loss: 0.0128, Training Acc: 0.9948\n",
            "Epoch: 70, Loss: 0.0128, Training Acc: 0.9948\n",
            "Epoch: 80, Loss: 0.0128, Training Acc: 0.9948\n",
            "Epoch: 90, Loss: 0.0128, Training Acc: 0.9948\n",
            "Epoch: 100, Loss: 0.0127, Training Acc: 0.9948\n",
            "Epoch: 110, Loss: 0.0127, Training Acc: 0.9948\n",
            "Epoch: 120, Loss: 0.0127, Training Acc: 0.9948\n",
            "Epoch: 130, Loss: 0.0127, Training Acc: 0.9948\n",
            "Epoch: 140, Loss: 0.0127, Training Acc: 0.9948\n",
            "Epoch: 150, Loss: 0.0127, Training Acc: 0.9948\n",
            "Epoch: 160, Loss: 0.0127, Training Acc: 0.9948\n",
            "Epoch: 170, Loss: 0.0127, Training Acc: 0.9948\n",
            "Epoch: 180, Loss: 0.0127, Training Acc: 0.9948\n",
            "Epoch: 190, Loss: 0.0127, Training Acc: 0.9948\n",
            "Epoch: 200, Loss: 0.0127, Training Acc: 0.9948\n",
            "Epoch: 210, Loss: 0.0127, Training Acc: 0.9948\n",
            "Epoch: 220, Loss: 0.0127, Training Acc: 0.9948\n",
            "Epoch: 230, Loss: 0.0126, Training Acc: 0.9948\n",
            "Epoch: 240, Loss: 0.0126, Training Acc: 0.9948\n",
            "Epoch: 250, Loss: 0.0126, Training Acc: 0.9948\n",
            "Epoch: 260, Loss: 0.0126, Training Acc: 0.9948\n",
            "Epoch: 270, Loss: 0.0126, Training Acc: 0.9948\n",
            "Epoch: 280, Loss: 0.0126, Training Acc: 0.9948\n",
            "Epoch: 290, Loss: 0.0126, Training Acc: 0.9948\n",
            "Epoch: 300, Loss: 0.0126, Training Acc: 0.9948\n",
            "Training time: 32.74152326583862 seconds\n"
          ]
        }
      ],
      "source": [
        "# train the model\n",
        "def compute_accuracy(pred_y, y):\n",
        "    return (pred_y == y).sum()\n",
        "\n",
        "import time\n",
        "\n",
        "# Start recording the current time\n",
        "start_time = time.time()\n",
        "\n",
        "\n",
        "model.train()\n",
        "losses = []\n",
        "accuracies = []\n",
        "for epoch in range(300):\n",
        "  optimizer.zero_grad()\n",
        "  out = model(cora.x, cora.edge_index)\n",
        "  loss = torch.nn.functional.nll_loss(out[~test_mask], cora.y[~test_mask])\n",
        "  correct = compute_accuracy(out[~test_mask].argmax(dim=1), cora.y[~test_mask])\n",
        "  acc = int(correct) / (len(test_mask)-int(test_mask.int().sum()))\n",
        "  losses.append(loss.item())\n",
        "  accuracies.append(acc)\n",
        "\n",
        "  # torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
        "\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "  if (epoch+1) % 10 == 0:\n",
        "    print('Epoch: {}, Loss: {:.4f}, Training Acc: {:.4f}'.format(epoch+1, loss.item(), acc))\n",
        "\n",
        "# End recording the current time\n",
        "end_time = time.time()\n",
        "\n",
        "# Calculate the elapsed time\n",
        "elapsed_time = end_time - start_time\n",
        "\n",
        "print(\"Training time:\", elapsed_time, \"seconds\")\n",
        "\n",
        "torch.save(model.state_dict(), model_save_path_GraphSage)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "59fbf1cb-c9a7-4d6f-b353-0898646a59b7",
      "metadata": {
        "id": "59fbf1cb-c9a7-4d6f-b353-0898646a59b7"
      },
      "source": [
        "# GCN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "id": "89de4220-ff7c-48b7-8645-f2d9df53968a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "89de4220-ff7c-48b7-8645-f2d9df53968a",
        "outputId": "ed47a291-81e3-45a8-c37e-b4e1e65c3656"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inference time: 0.059253692626953125 seconds\n",
            "Accuracy: 0.5328\n"
          ]
        }
      ],
      "source": [
        "# evaluate the model on test set\n",
        "# best_model = GCN()\n",
        "# best_model.load_state_dict(torch.load(model_save_path_GCN))\n",
        "\n",
        "\n",
        "import time\n",
        "start_time = time.time()\n",
        "model.eval()\n",
        "pred = model(cora.x, cora.edge_index).argmax(dim=1)\n",
        "# correct = compute_accuracy(pred, test_data.y)\n",
        "\n",
        "# End recording the current time\n",
        "end_time = time.time()\n",
        "\n",
        "# Calculate the elapsed time\n",
        "elapsed_time = end_time - start_time\n",
        "\n",
        "print(\"Inference time:\", elapsed_time, \"seconds\")\n",
        "correct = compute_accuracy(pred[test_mask], cora.y[test_mask])\n",
        "# acc = int(correct) / len(test_data.y)\n",
        "acc = int(correct) / len(tested_elements)\n",
        "print(f'Accuracy: {acc:.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1h5sIdR17Plv",
      "metadata": {
        "id": "1h5sIdR17Plv"
      },
      "source": [
        "# alpha = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "id": "ZhM2RLaZRmLO",
      "metadata": {
        "id": "ZhM2RLaZRmLO"
      },
      "outputs": [],
      "source": [
        "list2 = tested_elements\n",
        "list1 = list(G.nodes)\n",
        "\n",
        "indices = [list1.index(x) for x in list2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "id": "rKOjTAMw7Qn5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 484
        },
        "id": "rKOjTAMw7Qn5",
        "outputId": "b0254b90-e092-47a2-b302-457ac77e9ff4"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Error(s) in loading state_dict for GCN:\n\tMissing key(s) in state_dict: \"conv1.bias\", \"conv1.lin.weight\", \"conv2.bias\", \"conv2.lin.weight\", \"conv3.bias\", \"conv3.lin.weight\", \"bc3.module.weight\", \"bc3.module.bias\", \"bc3.module.running_mean\", \"bc3.module.running_var\". \n\tUnexpected key(s) in state_dict: \"conv1.lin_l.weight\", \"conv1.lin_l.bias\", \"conv1.lin_r.weight\", \"conv2.lin_l.weight\", \"conv2.lin_l.bias\", \"conv2.lin_r.weight\". \n\tsize mismatch for bc2.module.weight: copying a param with shape torch.Size([7]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for bc2.module.bias: copying a param with shape torch.Size([7]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for bc2.module.running_mean: copying a param with shape torch.Size([7]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for bc2.module.running_var: copying a param with shape torch.Size([7]) from checkpoint, the shape in current model is torch.Size([128]).",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2686360250.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# Create model with correct arguments\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mbest_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGCN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mbest_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_save_path_GCN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[1;32m   2627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2628\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2629\u001b[0;31m             raise RuntimeError(\n\u001b[0m\u001b[1;32m   2630\u001b[0m                 \"Error(s) in loading state_dict for {}:\\n\\t{}\".format(\n\u001b[1;32m   2631\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\\n\\t\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for GCN:\n\tMissing key(s) in state_dict: \"conv1.bias\", \"conv1.lin.weight\", \"conv2.bias\", \"conv2.lin.weight\", \"conv3.bias\", \"conv3.lin.weight\", \"bc3.module.weight\", \"bc3.module.bias\", \"bc3.module.running_mean\", \"bc3.module.running_var\". \n\tUnexpected key(s) in state_dict: \"conv1.lin_l.weight\", \"conv1.lin_l.bias\", \"conv1.lin_r.weight\", \"conv2.lin_l.weight\", \"conv2.lin_l.bias\", \"conv2.lin_r.weight\". \n\tsize mismatch for bc2.module.weight: copying a param with shape torch.Size([7]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for bc2.module.bias: copying a param with shape torch.Size([7]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for bc2.module.running_mean: copying a param with shape torch.Size([7]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for bc2.module.running_var: copying a param with shape torch.Size([7]) from checkpoint, the shape in current model is torch.Size([128])."
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import time\n",
        "\n",
        "list2 = tested_elements\n",
        "list1 = list(G.nodes)\n",
        "\n",
        "indices = [list1.index(x) for x in list2]\n",
        "\n",
        "# Get num_features and num_classes from your data\n",
        "num_features = cora.x.shape[1]  # or data.x.shape[1]\n",
        "num_classes = len(torch.unique(cora.y))  # or data.y\n",
        "\n",
        "# Create model with correct arguments\n",
        "best_model = GCN(num_features, num_classes)\n",
        "best_model.load_state_dict(torch.load(model_save_path_GCN))\n",
        "\n",
        "start_time = time.time()\n",
        "best_model.eval()\n",
        "pred = best_model(data_new1.x, data_new1.edge_index).argmax(dim=1)\n",
        "\n",
        "# End recording the current time\n",
        "end_time = time.time()\n",
        "\n",
        "# Calculate the elapsed time\n",
        "elapsed_time = end_time - start_time\n",
        "\n",
        "print(\"Inference time:\", elapsed_time, \"seconds\")\n",
        "correct = compute_accuracy(pred[indices], data_new1.y[indices])\n",
        "acc = int(correct) / len(tested_elements)\n",
        "print(f'Accuracy: {acc:.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4n8krggX1qLB",
      "metadata": {
        "id": "4n8krggX1qLB"
      },
      "source": [
        "# alpha = 0.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "17581b6c-fcc2-4b91-a271-9e820e37596f",
      "metadata": {
        "id": "17581b6c-fcc2-4b91-a271-9e820e37596f"
      },
      "outputs": [],
      "source": [
        "best_model = GCN()\n",
        "best_model.load_state_dict(torch.load(model_save_path_GCN))\n",
        "\n",
        "start_time = time.time()\n",
        "best_model.eval()\n",
        "pred = best_model(data_new1.x, data_new1.edge_index).argmax(dim=1)\n",
        "\n",
        "# End recording the current time\n",
        "end_time = time.time()\n",
        "\n",
        "# Calculate the elapsed time\n",
        "elapsed_time = end_time - start_time\n",
        "\n",
        "print(\"Inference time:\", elapsed_time, \"seconds\")\n",
        "correct = compute_accuracy(pred[indices], data_new1.y[indices])\n",
        "acc = int(correct) / len(tested_elements)\n",
        "print(f'Accuracy: {acc:.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "vLoqf51cZVY0",
      "metadata": {
        "id": "vLoqf51cZVY0"
      },
      "source": [
        "# alpha = 0.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7FfBMb4DZVhK",
      "metadata": {
        "id": "7FfBMb4DZVhK"
      },
      "outputs": [],
      "source": [
        "best_model = GCN()\n",
        "best_model.load_state_dict(torch.load(model_save_path_GCN))\n",
        "\n",
        "start_time = time.time()\n",
        "best_model.eval()\n",
        "pred = best_model(data_new1.x, data_new1.edge_index).argmax(dim=1)\n",
        "\n",
        "# End recording the current time\n",
        "end_time = time.time()\n",
        "\n",
        "# Calculate the elapsed time\n",
        "elapsed_time = end_time - start_time\n",
        "\n",
        "print(\"Inference time:\", elapsed_time, \"seconds\")\n",
        "correct = compute_accuracy(pred[indices], data_new1.y[indices])\n",
        "acc = int(correct) / len(tested_elements)\n",
        "print(f'Accuracy: {acc:.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Dv_waQR7b4Zn",
      "metadata": {
        "id": "Dv_waQR7b4Zn"
      },
      "source": [
        "# 0.3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "JUGHCHtyb4ig",
      "metadata": {
        "id": "JUGHCHtyb4ig"
      },
      "outputs": [],
      "source": [
        "best_model = GCN()\n",
        "best_model.load_state_dict(torch.load(model_save_path_GCN))\n",
        "\n",
        "start_time = time.time()\n",
        "best_model.eval()\n",
        "pred = best_model(data_new1.x, data_new1.edge_index).argmax(dim=1)\n",
        "\n",
        "# End recording the current time\n",
        "end_time = time.time()\n",
        "\n",
        "# Calculate the elapsed time\n",
        "elapsed_time = end_time - start_time\n",
        "\n",
        "print(\"Inference time:\", elapsed_time, \"seconds\")\n",
        "correct = compute_accuracy(pred[indices], data_new1.y[indices])\n",
        "acc = int(correct) / len(tested_elements)\n",
        "print(f'Accuracy: {acc:.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dRBwDIjhmlyr",
      "metadata": {
        "id": "dRBwDIjhmlyr"
      },
      "source": [
        "# 0.4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "KgyjOrcNml5-",
      "metadata": {
        "id": "KgyjOrcNml5-"
      },
      "outputs": [],
      "source": [
        "best_model = GCN()\n",
        "best_model.load_state_dict(torch.load(model_save_path_GCN))\n",
        "\n",
        "start_time = time.time()\n",
        "best_model.eval()\n",
        "pred = best_model(data_new1.x, data_new1.edge_index).argmax(dim=1)\n",
        "\n",
        "# End recording the current time\n",
        "end_time = time.time()\n",
        "\n",
        "# Calculate the elapsed time\n",
        "elapsed_time = end_time - start_time\n",
        "\n",
        "print(\"Inference time:\", elapsed_time, \"seconds\")\n",
        "correct = compute_accuracy(pred[indices], data_new1.y[indices])\n",
        "acc = int(correct) / len(tested_elements)\n",
        "print(f'Accuracy: {acc:.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "lC_OZ5icoT_Q",
      "metadata": {
        "id": "lC_OZ5icoT_Q"
      },
      "source": [
        "# 0.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f6OtGpfLoUG0",
      "metadata": {
        "id": "f6OtGpfLoUG0"
      },
      "outputs": [],
      "source": [
        "best_model = GCN()\n",
        "best_model.load_state_dict(torch.load(model_save_path_GCN))\n",
        "\n",
        "start_time = time.time()\n",
        "best_model.eval()\n",
        "pred = best_model(data_new1.x, data_new1.edge_index).argmax(dim=1)\n",
        "\n",
        "# End recording the current time\n",
        "end_time = time.time()\n",
        "\n",
        "# Calculate the elapsed time\n",
        "elapsed_time = end_time - start_time\n",
        "\n",
        "print(\"Inference time:\", elapsed_time, \"seconds\")\n",
        "correct = compute_accuracy(pred[indices], data_new1.y[indices])\n",
        "acc = int(correct) / len(tested_elements)\n",
        "print(f'Accuracy: {acc:.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "KevUIMuB7Ghl",
      "metadata": {
        "id": "KevUIMuB7Ghl"
      },
      "source": [
        "# alpha = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "pRvqcst_KZpl",
      "metadata": {
        "id": "pRvqcst_KZpl"
      },
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "import random\n",
        "\n",
        "new_x = torch.zeros(num_nodes,data.x.shape[1])\n",
        "new_y = torch.zeros(num_nodes)\n",
        "for i in range(len(list_of_tuples)):\n",
        "    sum_node_degree = 0\n",
        "    for ele in list_of_tuples[i]:\n",
        "        sum_node_degree += G.out_degree(ele)\n",
        "    new_node_degree = BCG.out_degree(i)\n",
        "    if new_node_degree != 0:\n",
        "        scalar = sum_node_degree/new_node_degree\n",
        "\n",
        "    else:\n",
        "        scalar = 1\n",
        "\n",
        "\n",
        "    new_x[i,:] = scalar * torch.mean(data.x[list(list_of_tuples[i]),:], axis = 0)\n",
        "    EC = list_of_tuples[i]\n",
        "    L = []\n",
        "    for ele in EC:\n",
        "        L.append(int(data.y[ele].numpy()))\n",
        "\n",
        "    keys = list(Counter(L).keys())\n",
        "    frequencies = list(Counter(L).values())\n",
        "\n",
        "    # Randomly select a key based on frequencies\n",
        "    random_key = random.choices(keys, frequencies)[0]\n",
        "    new_y[i] = int(random_key)\n",
        "\n",
        "edges = list(BCG.edges())\n",
        "\n",
        "# Create a dictionary to map node labels to integer indices\n",
        "node_mapping = {node: index for index, node in enumerate(BCG.nodes())}\n",
        "\n",
        "# Convert the edges to indices using the node_mapping\n",
        "new_edge_index = [[node_mapping[source], node_mapping[target]] for source, target in edges]\n",
        "new_edge_index = torch.tensor(new_edge_index, dtype=torch.long).t().contiguous()\n",
        "\n",
        "data_new1 = copy.copy(data)\n",
        "data_new1.x = new_x\n",
        "data_new1.y = new_y.long()\n",
        "data_new1.edge_index = new_edge_index\n",
        "data_new1.num_nodes = len(new_y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Eyw5pUKTKd1r",
      "metadata": {
        "id": "Eyw5pUKTKd1r"
      },
      "outputs": [],
      "source": [
        "# best_model = GCN()\n",
        "# best_model.load_state_dict(torch.load(model_save_path_GCN))\n",
        "\n",
        "start_time = time.time()\n",
        "model.eval()\n",
        "pred = model(data_new1.x, data_new1.edge_index).argmax(dim=1)\n",
        "\n",
        "# End recording the current time\n",
        "end_time = time.time()\n",
        "\n",
        "# Calculate the elapsed time\n",
        "elapsed_time = end_time - start_time\n",
        "\n",
        "print(\"Inference time:\", elapsed_time, \"seconds\")\n",
        "correct = compute_accuracy(pred[indices], data_new1.y[indices])\n",
        "acc = int(correct) / len(tested_elements)\n",
        "print(f'Accuracy: {acc:.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "MYupJvxh7Gso",
      "metadata": {
        "id": "MYupJvxh7Gso"
      },
      "outputs": [],
      "source": [
        "# best_model = GCN()\n",
        "# best_model.load_state_dict(torch.load(model_save_path_GCN))\n",
        "\n",
        "start_time = time.time()\n",
        "model.eval()\n",
        "pred = model(data_new1.x, data_new1.edge_index).argmax(dim=1)\n",
        "\n",
        "# End recording the current time\n",
        "end_time = time.time()\n",
        "\n",
        "# Calculate the elapsed time\n",
        "elapsed_time = end_time - start_time\n",
        "\n",
        "print(\"Inference time:\", elapsed_time, \"seconds\")\n",
        "correct = compute_accuracy(pred[indices], data_new1.y[indices])\n",
        "acc = int(correct) / len(tested_elements)\n",
        "print(f'Accuracy: {acc:.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f5bfdd3f-6dc1-4c7f-baf3-c0948afe04e7",
      "metadata": {
        "id": "f5bfdd3f-6dc1-4c7f-baf3-c0948afe04e7"
      },
      "source": [
        "# GAT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e383ee92-7125-4703-8782-9b6e98817b76",
      "metadata": {
        "id": "e383ee92-7125-4703-8782-9b6e98817b76"
      },
      "outputs": [],
      "source": [
        "# evaluate the model on test set\n",
        "best_model = GAT()\n",
        "best_model.load_state_dict(torch.load(model_save_path_GAT))\n",
        "\n",
        "import time\n",
        "start_time = time.time()\n",
        "best_model.eval()\n",
        "pred = best_model(data.x, data.edge_index).argmax(dim=1)\n",
        "# correct = compute_accuracy(pred, test_data.y)\n",
        "\n",
        "# End recording the current time\n",
        "end_time = time.time()\n",
        "\n",
        "# Calculate the elapsed time\n",
        "elapsed_time = end_time - start_time\n",
        "\n",
        "print(\"Inference time:\", elapsed_time, \"seconds\")\n",
        "correct = compute_accuracy(pred[test_mask], data.y[test_mask])\n",
        "# acc = int(correct) / len(test_data.y)\n",
        "acc = int(correct) / len(tested_elements)\n",
        "print(f'Accuracy: {acc:.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Z8gCfDbRKA_y",
      "metadata": {
        "id": "Z8gCfDbRKA_y"
      },
      "source": [
        "# Alpha = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6bb6623d-19b9-4247-a4c5-fe4b38533c37",
      "metadata": {
        "id": "6bb6623d-19b9-4247-a4c5-fe4b38533c37"
      },
      "outputs": [],
      "source": [
        "best_model = GAT()\n",
        "best_model.load_state_dict(torch.load(model_save_path_GAT))\n",
        "\n",
        "start_time = time.time()\n",
        "best_model.eval()\n",
        "pred = best_model(data_new1.x, data_new1.edge_index).argmax(dim=1)\n",
        "\n",
        "# End recording the current time\n",
        "end_time = time.time()\n",
        "\n",
        "# Calculate the elapsed time\n",
        "elapsed_time = end_time - start_time\n",
        "\n",
        "print(\"Inference time:\", elapsed_time, \"seconds\")\n",
        "correct = compute_accuracy(pred[indices], data_new1.y[indices])\n",
        "acc = int(correct) / len(tested_elements)\n",
        "print(f'Accuracy: {acc:.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "WcucCLYTWykP",
      "metadata": {
        "id": "WcucCLYTWykP"
      },
      "source": [
        "# Alpha = 0.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "wICgLSpdWytm",
      "metadata": {
        "id": "wICgLSpdWytm"
      },
      "outputs": [],
      "source": [
        "best_model = GAT()\n",
        "best_model.load_state_dict(torch.load(model_save_path_GAT))\n",
        "\n",
        "start_time = time.time()\n",
        "best_model.eval()\n",
        "pred = best_model(data_new1.x, data_new1.edge_index).argmax(dim=1)\n",
        "\n",
        "# End recording the current time\n",
        "end_time = time.time()\n",
        "\n",
        "# Calculate the elapsed time\n",
        "elapsed_time = end_time - start_time\n",
        "\n",
        "print(\"Inference time:\", elapsed_time, \"seconds\")\n",
        "correct = compute_accuracy(pred[indices], data_new1.y[indices])\n",
        "acc = int(correct) / len(tested_elements)\n",
        "print(f'Accuracy: {acc:.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "roAYjkDnZ6qB",
      "metadata": {
        "id": "roAYjkDnZ6qB"
      },
      "source": [
        "# Alpha = 0.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Vk3EsaffZ6xn",
      "metadata": {
        "id": "Vk3EsaffZ6xn"
      },
      "outputs": [],
      "source": [
        "best_model = GAT()\n",
        "best_model.load_state_dict(torch.load(model_save_path_GAT))\n",
        "\n",
        "start_time = time.time()\n",
        "best_model.eval()\n",
        "pred = best_model(data_new1.x, data_new1.edge_index).argmax(dim=1)\n",
        "\n",
        "# End recording the current time\n",
        "end_time = time.time()\n",
        "\n",
        "# Calculate the elapsed time\n",
        "elapsed_time = end_time - start_time\n",
        "\n",
        "print(\"Inference time:\", elapsed_time, \"seconds\")\n",
        "correct = compute_accuracy(pred[indices], data_new1.y[indices])\n",
        "acc = int(correct) / len(tested_elements)\n",
        "print(f'Accuracy: {acc:.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "51arSmxUcKXQ",
      "metadata": {
        "id": "51arSmxUcKXQ"
      },
      "source": [
        "# 0.3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "KKCF8bYAcKei",
      "metadata": {
        "id": "KKCF8bYAcKei"
      },
      "outputs": [],
      "source": [
        "best_model = GAT()\n",
        "best_model.load_state_dict(torch.load(model_save_path_GAT))\n",
        "\n",
        "start_time = time.time()\n",
        "best_model.eval()\n",
        "pred = best_model(data_new1.x, data_new1.edge_index).argmax(dim=1)\n",
        "\n",
        "# End recording the current time\n",
        "end_time = time.time()\n",
        "\n",
        "# Calculate the elapsed time\n",
        "elapsed_time = end_time - start_time\n",
        "\n",
        "print(\"Inference time:\", elapsed_time, \"seconds\")\n",
        "correct = compute_accuracy(pred[indices], data_new1.y[indices])\n",
        "acc = int(correct) / len(tested_elements)\n",
        "print(f'Accuracy: {acc:.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "heBTfapXm2h-",
      "metadata": {
        "id": "heBTfapXm2h-"
      },
      "source": [
        "# 0.4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "tXCx5xxDm2pG",
      "metadata": {
        "id": "tXCx5xxDm2pG"
      },
      "outputs": [],
      "source": [
        "best_model = GAT()\n",
        "best_model.load_state_dict(torch.load(model_save_path_GAT))\n",
        "\n",
        "start_time = time.time()\n",
        "best_model.eval()\n",
        "pred = best_model(data_new1.x, data_new1.edge_index).argmax(dim=1)\n",
        "\n",
        "# End recording the current time\n",
        "end_time = time.time()\n",
        "\n",
        "# Calculate the elapsed time\n",
        "elapsed_time = end_time - start_time\n",
        "\n",
        "print(\"Inference time:\", elapsed_time, \"seconds\")\n",
        "correct = compute_accuracy(pred[indices], data_new1.y[indices])\n",
        "acc = int(correct) / len(tested_elements)\n",
        "print(f'Accuracy: {acc:.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "YOqvWY-QeJ3w",
      "metadata": {
        "id": "YOqvWY-QeJ3w"
      },
      "source": [
        "# 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "AQfzD8nNeJ_h",
      "metadata": {
        "id": "AQfzD8nNeJ_h"
      },
      "outputs": [],
      "source": [
        "best_model = GAT()\n",
        "best_model.load_state_dict(torch.load(model_save_path_GAT))\n",
        "\n",
        "start_time = time.time()\n",
        "best_model.eval()\n",
        "pred = best_model(data_new1.x, data_new1.edge_index).argmax(dim=1)\n",
        "\n",
        "# End recording the current time\n",
        "end_time = time.time()\n",
        "\n",
        "# Calculate the elapsed time\n",
        "elapsed_time = end_time - start_time\n",
        "\n",
        "print(\"Inference time:\", elapsed_time, \"seconds\")\n",
        "correct = compute_accuracy(pred[indices], data_new1.y[indices])\n",
        "acc = int(correct) / len(tested_elements)\n",
        "print(f'Accuracy: {acc:.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e5b1d592-e622-4a45-ae81-550632d112e1",
      "metadata": {
        "id": "e5b1d592-e622-4a45-ae81-550632d112e1"
      },
      "outputs": [],
      "source": [
        "(0.5725-0.5224)/0.5725"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "sDgGO5SQHSie",
      "metadata": {
        "id": "sDgGO5SQHSie"
      },
      "outputs": [],
      "source": [
        "model_save_path_GraphSage"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6a75da11-fd1a-426a-90c2-fa520badea39",
      "metadata": {
        "id": "6a75da11-fd1a-426a-90c2-fa520badea39"
      },
      "source": [
        "# GraphSage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "58d69666-0adc-49cf-994a-88dabdb4f3e4",
      "metadata": {
        "id": "58d69666-0adc-49cf-994a-88dabdb4f3e4"
      },
      "outputs": [],
      "source": [
        "best_model = GraphSAGE()\n",
        "best_model.load_state_dict(torch.load(model_save_path_GraphSage))\n",
        "\n",
        "# evaluate the model on test set\n",
        "import time\n",
        "start_time = time.time()\n",
        "best_model.eval()\n",
        "pred = best_model(data.x, data.edge_index).argmax(dim=1)\n",
        "# correct = compute_accuracy(pred, test_data.y)\n",
        "\n",
        "# End recording the current time\n",
        "end_time = time.time()\n",
        "\n",
        "# Calculate the elapsed time\n",
        "elapsed_time = end_time - start_time\n",
        "\n",
        "print(\"Inference time:\", elapsed_time, \"seconds\")\n",
        "correct = compute_accuracy(pred[test_mask], data.y[test_mask])\n",
        "# acc = int(correct) / len(test_data.y)\n",
        "acc = int(correct) / len(tested_elements)\n",
        "print(f'Accuracy: {acc:.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "WcKQTglkPI5Y",
      "metadata": {
        "id": "WcKQTglkPI5Y"
      },
      "source": [
        "# Alpha = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "O0FSE3r_TRHC",
      "metadata": {
        "id": "O0FSE3r_TRHC"
      },
      "outputs": [],
      "source": [
        "list2 = tested_elements\n",
        "list1 = list(G.nodes)\n",
        "\n",
        "indices = [list1.index(x) for x in list2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1885adf1-706b-463a-90d6-3820f8e02151",
      "metadata": {
        "id": "1885adf1-706b-463a-90d6-3820f8e02151"
      },
      "outputs": [],
      "source": [
        "# evaluate the model on test set\n",
        "start_time = time.time()\n",
        "model.eval()\n",
        "pred = model(data_new1.x, data_new1.edge_index).argmax(dim=1)\n",
        "\n",
        "# End recording the current time\n",
        "end_time = time.time()\n",
        "\n",
        "# Calculate the elapsed time\n",
        "elapsed_time = end_time - start_time\n",
        "\n",
        "print(\"Inference time:\", elapsed_time, \"seconds\")\n",
        "correct = compute_accuracy(pred[indices], data_new1.y[indices])\n",
        "acc = int(correct) / len(tested_elements)\n",
        "print(f'Accuracy: {acc:.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "hTEktS_ZXlhH",
      "metadata": {
        "id": "hTEktS_ZXlhH"
      },
      "source": [
        "# Alpha = 0.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7d609d14-193e-49d7-9e82-f21e058f38ea",
      "metadata": {
        "id": "7d609d14-193e-49d7-9e82-f21e058f38ea"
      },
      "outputs": [],
      "source": [
        "best_model = GraphSAGE()\n",
        "best_model.load_state_dict(torch.load(model_save_path_GraphSage))\n",
        "\n",
        "start_time = time.time()\n",
        "best_model.eval()\n",
        "pred = best_model(data_new1.x, data_new1.edge_index).argmax(dim=1)\n",
        "\n",
        "# End recording the current time\n",
        "end_time = time.time()\n",
        "\n",
        "# Calculate the elapsed time\n",
        "elapsed_time = end_time - start_time\n",
        "\n",
        "print(\"Inference time:\", elapsed_time, \"seconds\")\n",
        "correct = compute_accuracy(pred[indices], data_new1.y[indices])\n",
        "acc = int(correct) / len(tested_elements)\n",
        "print(f'Accuracy: {acc:.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Xu8fbuhJadmh",
      "metadata": {
        "id": "Xu8fbuhJadmh"
      },
      "source": [
        "# Alpha = 0.2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "blEY9AB5aciS",
      "metadata": {
        "id": "blEY9AB5aciS"
      },
      "outputs": [],
      "source": [
        "best_model = GraphSAGE()\n",
        "best_model.load_state_dict(torch.load(model_save_path_GraphSage))\n",
        "\n",
        "start_time = time.time()\n",
        "best_model.eval()\n",
        "pred = best_model(data_new1.x, data_new1.edge_index).argmax(dim=1)\n",
        "\n",
        "# End recording the current time\n",
        "end_time = time.time()\n",
        "\n",
        "# Calculate the elapsed time\n",
        "elapsed_time = end_time - start_time\n",
        "\n",
        "print(\"Inference time:\", elapsed_time, \"seconds\")\n",
        "correct = compute_accuracy(pred[indices], data_new1.y[indices])\n",
        "acc = int(correct) / len(tested_elements)\n",
        "print(f'Accuracy: {acc:.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "hLrpNB62cbwK",
      "metadata": {
        "id": "hLrpNB62cbwK"
      },
      "source": [
        "# 0.3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "_HxFb9yYcb5n",
      "metadata": {
        "id": "_HxFb9yYcb5n"
      },
      "outputs": [],
      "source": [
        "best_model = GraphSAGE()\n",
        "best_model.load_state_dict(torch.load(model_save_path_GraphSage))\n",
        "\n",
        "start_time = time.time()\n",
        "best_model.eval()\n",
        "pred = best_model(data_new1.x, data_new1.edge_index).argmax(dim=1)\n",
        "\n",
        "# End recording the current time\n",
        "end_time = time.time()\n",
        "\n",
        "# Calculate the elapsed time\n",
        "elapsed_time = end_time - start_time\n",
        "\n",
        "print(\"Inference time:\", elapsed_time, \"seconds\")\n",
        "correct = compute_accuracy(pred[indices], data_new1.y[indices])\n",
        "acc = int(correct) / len(tested_elements)\n",
        "print(f'Accuracy: {acc:.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "sHqLotJGnJBb",
      "metadata": {
        "id": "sHqLotJGnJBb"
      },
      "source": [
        "# 0.4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0etRrrDnnJIj",
      "metadata": {
        "id": "0etRrrDnnJIj"
      },
      "outputs": [],
      "source": [
        "best_model = GraphSAGE()\n",
        "best_model.load_state_dict(torch.load(model_save_path_GraphSage))\n",
        "\n",
        "start_time = time.time()\n",
        "best_model.eval()\n",
        "pred = best_model(data_new1.x, data_new1.edge_index).argmax(dim=1)\n",
        "\n",
        "# End recording the current time\n",
        "end_time = time.time()\n",
        "\n",
        "# Calculate the elapsed time\n",
        "elapsed_time = end_time - start_time\n",
        "\n",
        "print(\"Inference time:\", elapsed_time, \"seconds\")\n",
        "correct = compute_accuracy(pred[indices], data_new1.y[indices])\n",
        "acc = int(correct) / len(tested_elements)\n",
        "print(f'Accuracy: {acc:.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "DcfvujGGefXX",
      "metadata": {
        "id": "DcfvujGGefXX"
      },
      "source": [
        "# 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "MaOZ5Sbnefer",
      "metadata": {
        "id": "MaOZ5Sbnefer"
      },
      "outputs": [],
      "source": [
        "best_model = GraphSAGE()\n",
        "best_model.load_state_dict(torch.load(model_save_path_GraphSage))\n",
        "\n",
        "start_time = time.time()\n",
        "best_model.eval()\n",
        "pred = best_model(data_new1.x, data_new1.edge_index).argmax(dim=1)\n",
        "\n",
        "# End recording the current time\n",
        "end_time = time.time()\n",
        "\n",
        "# Calculate the elapsed time\n",
        "elapsed_time = end_time - start_time\n",
        "\n",
        "print(\"Inference time:\", elapsed_time, \"seconds\")\n",
        "correct = compute_accuracy(pred[indices], data_new1.y[indices])\n",
        "acc = int(correct) / len(tested_elements)\n",
        "print(f'Accuracy: {acc:.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f52ad826-8813-408c-ac0e-8cce89b1413f",
      "metadata": {
        "id": "f52ad826-8813-408c-ac0e-8cce89b1413f"
      },
      "outputs": [],
      "source": [
        "# evaluate the model on test set\n",
        "list2 = tested_elements\n",
        "list1 = list(G.nodes)\n",
        "\n",
        "indices = [list1.index(x) for x in list2]\n",
        "\n",
        "start_time = time.time()\n",
        "model.eval()\n",
        "pred = model(data_new1.x, data_new1.edge_index).argmax(dim=1)\n",
        "\n",
        "# End recording the current time\n",
        "end_time = time.time()\n",
        "\n",
        "# Calculate the elapsed time\n",
        "elapsed_time = end_time - start_time\n",
        "\n",
        "print(\"Inference time:\", elapsed_time, \"seconds\")\n",
        "correct = compute_accuracy(pred[indices], data_new1.y[indices])\n",
        "acc = int(correct) / len(tested_elements)\n",
        "print(f'Accuracy: {acc:.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import time\n",
        "from torch_geometric.nn import GCNConv, GATConv, SAGEConv, BatchNorm\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# ============================================================================\n",
        "# DEFINE GNN MODELS\n",
        "# ============================================================================\n",
        "\n",
        "class GCN(torch.nn.Module):\n",
        "    def __init__(self, num_features, num_classes):\n",
        "        super().__init__()\n",
        "        self.conv1 = GCNConv(num_features, 128, aggr='mean')\n",
        "        self.bc1 = BatchNorm(128)\n",
        "        self.conv2 = GCNConv(128, 128, aggr='mean')\n",
        "        self.bc2 = BatchNorm(128)\n",
        "        self.conv3 = GCNConv(128, num_classes, aggr='mean')\n",
        "        self.bc3 = BatchNorm(num_classes)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = self.bc1(x)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = self.bc2(x)\n",
        "        x = self.conv3(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = self.bc3(x)\n",
        "        return F.log_softmax(x, dim=1)\n",
        "\n",
        "class GAT(torch.nn.Module):\n",
        "    def __init__(self, num_features, num_classes):\n",
        "        super().__init__()\n",
        "        self.conv1 = GATConv(num_features, 128, heads=8, aggr='mean')\n",
        "        self.bc1 = BatchNorm(128 * 8)\n",
        "        self.conv2 = GATConv(128 * 8, 128, heads=8, aggr='mean')\n",
        "        self.bc2 = BatchNorm(128 * 8)\n",
        "        self.conv3 = GATConv(128 * 8, num_classes, heads=1, aggr='mean')\n",
        "        self.bc3 = BatchNorm(num_classes)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = self.bc1(x)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = self.bc2(x)\n",
        "        x = self.conv3(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = self.bc3(x)\n",
        "        return F.log_softmax(x, dim=1)\n",
        "\n",
        "class GraphSAGE(torch.nn.Module):\n",
        "    def __init__(self, num_features, num_classes):\n",
        "        super().__init__()\n",
        "        self.conv1 = SAGEConv(num_features, 128)\n",
        "        self.bc1 = BatchNorm(128)\n",
        "        self.conv2 = SAGEConv(128, 128)\n",
        "        self.bc2 = BatchNorm(128)\n",
        "        self.conv3 = SAGEConv(128, num_classes)\n",
        "        self.bc3 = BatchNorm(num_classes)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = self.bc1(x)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = self.bc2(x)\n",
        "        x = self.conv3(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = self.bc3(x)\n",
        "        return F.log_softmax(x, dim=1)\n",
        "\n",
        "# ============================================================================\n",
        "# INFERENCE TIMING FUNCTION\n",
        "# ============================================================================\n",
        "\n",
        "def measure_inference_time(model, data, num_runs=5):\n",
        "    \"\"\"Measure average inference time over multiple runs\"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    # Warm-up run\n",
        "    with torch.no_grad():\n",
        "        _ = model(data.x, data.edge_index)\n",
        "\n",
        "    # Measure inference time over multiple runs\n",
        "    times = []\n",
        "    for _ in range(num_runs):\n",
        "        torch.cuda.synchronize() if torch.cuda.is_available() else None\n",
        "\n",
        "        start_time = time.time()\n",
        "        with torch.no_grad():\n",
        "            _ = model(data.x, data.edge_index)\n",
        "        end_time = time.time()\n",
        "\n",
        "        times.append(end_time - start_time)\n",
        "\n",
        "    # Return average time\n",
        "    avg_time = sum(times) / len(times)\n",
        "    return avg_time\n",
        "\n",
        "# ============================================================================\n",
        "# COLLECT INFERENCE TIMES AND GENERATE FIGURE 7\n",
        "# ============================================================================\n",
        "\n",
        "def collect_inference_times_and_plot(original_data=None, compressed_data=None, device='cpu'):\n",
        "    \"\"\"\n",
        "    Create, train GNN models, measure inference times, and generate Figure 7\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    original_data : torch_geometric.data.Data, optional\n",
        "        Original graph. If None, will use 'cora' from globals\n",
        "    compressed_data : torch_geometric.data.Data, optional\n",
        "        Compressed graph. If None, will use 'datanew1' from globals\n",
        "    device : str\n",
        "        Device to use ('cpu' or 'cuda')\n",
        "    \"\"\"\n",
        "\n",
        "    # ====== STEP 1: Get data ======\n",
        "    if original_data is None:\n",
        "        if 'cora' in globals():\n",
        "            original_data = globals()['cora']\n",
        "            print(\" Using 'cora' from notebook globals\")\n",
        "        else:\n",
        "            raise NameError(\"'cora' not found. Please ensure 'cora' is available in notebook.\")\n",
        "\n",
        "    if compressed_data is None:\n",
        "        if 'datanew1' in globals():\n",
        "            compressed_data = globals()['datanew1']\n",
        "            print(\" Using 'datanew1' from notebook globals\")\n",
        "        else:\n",
        "            raise NameError(\"'datanew1' not found. Please ensure 'datanew1' is available in notebook.\")\n",
        "\n",
        "    original_data = original_data.to(device)\n",
        "    compressed_data = compressed_data.to(device)\n",
        "\n",
        "    num_features = original_data.x.shape[1]\n",
        "    num_classes = len(torch.unique(original_data.y))\n",
        "\n",
        "    print(f\"\\n Original Graph: {original_data.num_nodes} nodes, {original_data.num_edges} edges\")\n",
        "    print(f\" Compressed Graph: {compressed_data.num_nodes} nodes, {compressed_data.num_edges} edges\")\n",
        "\n",
        "    # ====== STEP 2: Create models ======\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"STEP 1: TRAINING GNN MODELS\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    models = {\n",
        "        'GCN': GCN(num_features, num_classes),\n",
        "        'GAT': GAT(num_features, num_classes),\n",
        "        'GraphSAGE': GraphSAGE(num_features, num_classes)\n",
        "    }\n",
        "\n",
        "    # ====== STEP 3: Train each model ======\n",
        "    for gnn_name, model in models.items():\n",
        "        print(f\"\\nTraining {gnn_name}...\")\n",
        "        model = model.to(device)\n",
        "        optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "        # Training loop (10 epochs)\n",
        "        for epoch in range(10):\n",
        "            model.train()\n",
        "            optimizer.zero_grad()\n",
        "            out = model(original_data.x, original_data.edge_index)\n",
        "            loss = F.nll_loss(out[original_data.train_mask], original_data.y[original_data.train_mask])\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            if (epoch + 1) % 5 == 0:\n",
        "                print(f\"  Epoch {epoch+1}/10, Loss: {loss.item():.4f}\")\n",
        "\n",
        "        models[gnn_name] = model.cpu()\n",
        "\n",
        "    # ====== STEP 4: Measure inference times ======\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"STEP 2: MEASURING INFERENCE TIMES\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    original_times = {}\n",
        "    compressed_times = {}\n",
        "    speedups = {}\n",
        "\n",
        "    for gnn_name, model in models.items():\n",
        "        model = model.to(device)\n",
        "        model.eval()\n",
        "\n",
        "        print(f\"\\n{gnn_name}:\")\n",
        "        print(\"-\" * 40)\n",
        "\n",
        "        # Measure on original graph\n",
        "        orig_time = measure_inference_time(model, original_data, num_runs=5)\n",
        "        original_times[gnn_name] = orig_time\n",
        "        print(f\"  Original Graph: {orig_time:.6f}s\")\n",
        "\n",
        "        # Measure on compressed graph\n",
        "        comp_time = measure_inference_time(model, compressed_data, num_runs=5)\n",
        "        compressed_times[gnn_name] = comp_time\n",
        "        print(f\"  (0.5,1)-SPGC:  {comp_time:.6f}s\")\n",
        "\n",
        "        # Calculate speedup\n",
        "        speedup = orig_time / comp_time\n",
        "        speedups[gnn_name] = speedup\n",
        "        print(f\"  Speedup:       {speedup:.2f}x\")\n",
        "\n",
        "    # ====== STEP 5: Generate Figure 7 ======\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"STEP 3: GENERATING FIGURE 7\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    gnn_types = list(speedups.keys())\n",
        "    speedup_values = list(speedups.values())\n",
        "\n",
        "    # Create figure\n",
        "    fig, ax = plt.subplots(figsize=(10, 6))\n",
        "\n",
        "    # X positions\n",
        "    x = np.arange(len(gnn_types))\n",
        "    width = 0.5\n",
        "\n",
        "    # Colors: Red (GCN), Blue (GAT), Yellow (GraphSAGE)\n",
        "    colors = ['#d62728', '#1f77b4', '#ffbb78']\n",
        "\n",
        "    # Plot bars\n",
        "    bars = ax.bar(x, speedup_values, width, color=colors, edgecolor='black', linewidth=1.5)\n",
        "\n",
        "    # Add value labels on bars\n",
        "    for bar, speedup in zip(bars, speedup_values):\n",
        "        height = bar.get_height()\n",
        "        ax.text(bar.get_x() + bar.get_width()/2., height,\n",
        "               '{:.2f}x'.format(speedup),\n",
        "               ha='center', va='bottom', fontsize=11, fontweight='bold')\n",
        "\n",
        "    # Customize plot\n",
        "    ax.set_xlabel('GNN Architecture', fontsize=12, fontweight='bold')\n",
        "    ax.set_ylabel('Inference Speedup ()', fontsize=12, fontweight='bold')\n",
        "    ax.set_title('Figure 7: (0.5,1)-SPGC Inference Speedup (Cora)', fontsize=14, fontweight='bold')\n",
        "    ax.set_xticks(x)\n",
        "    ax.set_xticklabels(gnn_types, fontsize=11)\n",
        "    ax.grid(axis='y', alpha=0.3, linestyle='--')\n",
        "    ax.axhline(y=1.0, color='red', linestyle='--', linewidth=1.5, alpha=0.5)\n",
        "    ax.set_ylim(bottom=0, top=max(speedup_values) * 1.15)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # ====== STEP 6: Print summary ======\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"SUMMARY: (0.5,1)-SPGC INFERENCE SPEEDUP (Cora)\")\n",
        "    print(\"=\"*80)\n",
        "    print(\"{:<15} {:<20} {:<20} {:<15}\".format('GNN Type', 'Original Time (s)', '(0.5,1)-SPGC Time (s)', 'Speedup ()'))\n",
        "    print(\"-\"*80)\n",
        "\n",
        "    for gnn in gnn_types:\n",
        "        print(\"{:<15} {:<20.6f} {:<20.6f} {:<15.2f}x\".format(\n",
        "            gnn, original_times[gnn], compressed_times[gnn], speedups[gnn]))\n",
        "\n",
        "    print(\"=\"*80)\n",
        "    print(\"\\nNote: Speedup = Original Time / (0.5,1)-SPGC Time\")\n",
        "    print(\"Higher speedup values indicate better compression efficiency\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    return original_times, compressed_times, speedups\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# RUN THIS AT THE END OF YOUR NOTEBOOK\n",
        "# ============================================================================\n",
        "\n",
        "original_times, compressed_times, speedups = collect_inference_times_and_plot(\n",
        "    original_data=cora,\n",
        "    compressed_data=data_new1,\n",
        "    device='cuda' if torch.cuda.is_available() else 'cpu'\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "k6Nr80BziXwA",
        "outputId": "7cc33d79-94a7-44d7-c3bd-feee196daddd"
      },
      "id": "k6Nr80BziXwA",
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Original Graph: 2708 nodes, 5429 edges\n",
            " Compressed Graph: 1071 nodes, 858 edges\n",
            "\n",
            "================================================================================\n",
            "STEP 1: TRAINING GNN MODELS\n",
            "================================================================================\n",
            "\n",
            "Training GCN...\n",
            "  Epoch 5/10, Loss: 1.4724\n",
            "  Epoch 10/10, Loss: 1.2512\n",
            "\n",
            "Training GAT...\n",
            "  Epoch 5/10, Loss: 1.2850\n",
            "  Epoch 10/10, Loss: 1.0681\n",
            "\n",
            "Training GraphSAGE...\n",
            "  Epoch 5/10, Loss: 0.3346\n",
            "  Epoch 10/10, Loss: 0.2478\n",
            "\n",
            "================================================================================\n",
            "STEP 2: MEASURING INFERENCE TIMES\n",
            "================================================================================\n",
            "\n",
            "GCN:\n",
            "----------------------------------------\n",
            "  Original Graph: 0.029737s\n",
            "  (0.5,1)-SPGC:  0.012566s\n",
            "  Speedup:       2.37x\n",
            "\n",
            "GAT:\n",
            "----------------------------------------\n",
            "  Original Graph: 0.270872s\n",
            "  (0.5,1)-SPGC:  0.102098s\n",
            "  Speedup:       2.65x\n",
            "\n",
            "GraphSAGE:\n",
            "----------------------------------------\n",
            "  Original Graph: 0.061742s\n",
            "  (0.5,1)-SPGC:  0.022284s\n",
            "  Speedup:       2.77x\n",
            "\n",
            "================================================================================\n",
            "STEP 3: GENERATING FIGURE 7\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "SUMMARY: (0.5,1)-SPGC INFERENCE SPEEDUP (Cora)\n",
            "================================================================================\n",
            "GNN Type        Original Time (s)    (0.5,1)-SPGC Time (s) Speedup ()    \n",
            "--------------------------------------------------------------------------------\n",
            "GCN             0.029737             0.012566             2.37           x\n",
            "GAT             0.270872             0.102098             2.65           x\n",
            "GraphSAGE       0.061742             0.022284             2.77           x\n",
            "================================================================================\n",
            "\n",
            "Note: Speedup = Original Time / (0.5,1)-SPGC Time\n",
            "Higher speedup values indicate better compression efficiency\n",
            "================================================================================\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}